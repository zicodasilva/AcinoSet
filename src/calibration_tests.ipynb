{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from lib import app\n",
    "from lib.utils import load_points, save_points, load_json, save_json, load_dlc_points_as_df, load_scene\n",
    "from lib.plotting import plot_extrinsics\n",
    "from lib.calib import triangulate_points\n",
    "\n",
    "plt.style.use(os.path.join(\"..\", \"configs\", \"mplstyle.yaml\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_path = \"/Users/zico/Downloads/test2/calb_ext/manual_points/598\"\n",
    "ext_cam1_path = \"/Users/zico/Downloads/test2/calb_ext/manual_points/601\"\n",
    "ext_cam2_path = \"/Users/zico/Downloads/test2/calb_ext/manual_points/602\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_points(json_paths: list, out_fname: str):\n",
    "    data = load_json(json_paths[0])\n",
    "    output = {\n",
    "        \"board_shape\": [9, 1],\n",
    "        \"board_square_len\": 0,\n",
    "        \"camera_resolution\": [data[\"imageWidth\"], data[\"imageHeight\"]],\n",
    "        \"points\": {}\n",
    "    }\n",
    "    for fname in json_paths:\n",
    "        data = load_json(fname)\n",
    "        # assert len(data[\"shapes\"]) == 9, f\"File {fname} did not produce enough points\"\n",
    "        output[\"points\"][data[\"imagePath\"]] = []\n",
    "        for i, p in enumerate(data[\"shapes\"]):\n",
    "            # assert f\"p{i+1}\" == p[\"label\"]\n",
    "            output[\"points\"][data[\"imagePath\"]].append(p[\"points\"][0])\n",
    "\n",
    "    save_json(out_fname, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labelme points to acinoset points.\n",
    "# Convert intrinsic points.\n",
    "json_paths = sorted(glob(os.path.join(int_path, '*.json')))\n",
    "convert_points(json_paths, os.path.join(os.path.dirname(int_path), \"points3.json\"))\n",
    "\n",
    "# Convert extrinsic points.\n",
    "json_paths = sorted(glob(os.path.join(ext_cam1_path, '*.json')))\n",
    "convert_points(json_paths, os.path.join(os.path.dirname(ext_cam1_path), \"points1.json\"))\n",
    "\n",
    "json_paths = sorted(glob(os.path.join(ext_cam2_path, '*.json')))\n",
    "convert_points(json_paths, os.path.join(os.path.dirname(ext_cam2_path), \"points2.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather DLC labels of tail and spine and obtain pairwise points between the cameras to obtain an estimate of the extrinsics.\n",
    "def get_pairwise_points_from_df(points_2d_df, camera_pairs):\n",
    "    df_list = []\n",
    "    # get pairwise estimates\n",
    "    for cam_a, cam_b in camera_pairs:\n",
    "        d0 = points_2d_df[points_2d_df['camera'] == cam_a]\n",
    "        d1 = points_2d_df[points_2d_df['camera'] == cam_b]\n",
    "        intersection_df = d0.merge(d1, how='inner', on=['frame', 'marker'], suffixes=('_a', '_b'))\n",
    "        if intersection_df.shape[0] > 0:\n",
    "            print(f'Found {intersection_df.shape[0]} pairwise points between camera {cam_a} and {cam_b}')\n",
    "            df_list.append(intersection_df)\n",
    "        else:\n",
    "            print(f'No pairwise points between camera {cam_a} and {cam_b}')\n",
    "\n",
    "    return df_list\n",
    "\n",
    "\n",
    "def get_points_file(n_pts, fname):\n",
    "    try:\n",
    "        output = load_json(fname)\n",
    "    except FileNotFoundError:\n",
    "        output = {\n",
    "            \"board_shape\": [n_pts, 1],\n",
    "            \"board_square_len\": 0,\n",
    "            \"camera_resolution\": [0, 0],\n",
    "            \"points\": {}\n",
    "        }\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_pairwise_points(markers, points_df, cam_a_idx, cam_b_idx, out_dir):\n",
    "    output_a = get_points_file(len(markers), os.path.join(out_dir, f\"points{cam_a_idx+1}.json\"))\n",
    "    output_b = get_points_file(len(markers), os.path.join(out_dir, f\"points{cam_b_idx+1}.json\"))\n",
    "    frames = points_df[\"frame\"].unique()\n",
    "    for fno in frames:\n",
    "        temp_a = []\n",
    "        temp_b = []\n",
    "        for m in markers:\n",
    "            pts_a = points_df.query(f\"frame == {fno} and marker=='{m}'\")[[\"x_a\", \"y_a\"]].values\n",
    "            pts_b = points_df.query(f\"frame == {fno} and marker=='{m}'\")[[\"x_b\", \"y_b\"]].values\n",
    "            temp_a.append(pts_a.squeeze().tolist() if len(pts_a) > 0 else [np.nan, np.nan])\n",
    "            temp_b.append(pts_b.squeeze().tolist() if len(pts_b) > 0 else [np.nan, np.nan])\n",
    "        if len(np.asarray(temp_a, object).shape) == 2 and len(np.asarray(temp_b, object).shape) == 2:\n",
    "            # np.any(~np.isnan(temp_a)) and np.any(~np.isnan(temp_b))\n",
    "            output_a[\"points\"][f\"frame{fno}.png\"] = temp_a\n",
    "            output_b[\"points\"][f\"frame{fno}.png\"] = temp_b\n",
    "\n",
    "    save_json(os.path.join(out_dir, f\"points{cam_a_idx+1}.json\"), output_a)\n",
    "    save_json(os.path.join(out_dir, f\"points{cam_b_idx+1}.json\"), output_b)\n",
    "\n",
    "def plot_points_2d(points_fpath, cam_idx = 0):\n",
    "    points, _, _, _, _ = load_points(points_fpath)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(points[:, 0, 0], points[:, 0, 1], label=\"tail2\")\n",
    "    plt.scatter(points[:, 1, 0], points[:, 1, 1], label=\"r_back_paw\")\n",
    "    plt.scatter(points[:, 2, 0], points[:, 2, 1], label=\"l_front_ankle\")\n",
    "    plt.xlim((0, 800 if cam_idx < 2 else 1500))\n",
    "    plt.ylim((0, 600 if cam_idx < 2 else 500))\n",
    "    plt.legend()\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_points_3d(obj_pts, title):\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(2, 3)\n",
    "    # fig, ax = plt.subplots(2, 3)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    # ax[0, 0].plot(obj_pts[:, 0])\n",
    "    ax1.plot(obj_pts[:, 0])\n",
    "    ax1.set_title(\"X\")\n",
    "    # ax[0, 1].plot(obj_pts[:, 1])\n",
    "    ax2.plot(obj_pts[:, 1])\n",
    "    ax2.set_title(\"Y\")\n",
    "    # ax[0, 2].plot(obj_pts[:, 2])\n",
    "    ax3.plot(obj_pts[:, 1])\n",
    "    ax3.set_title(\"Z\")\n",
    "\n",
    "    # ax = fig.add_subplot(2, 3, (4, 5, 6), projection='3d')\n",
    "    ax4 = fig.add_subplot(gs[1, :], projection='3d')\n",
    "    ax4.scatter(obj_pts[:, 0], obj_pts[:, 1], obj_pts[:, 2])\n",
    "    ax4.set_xlabel(\"X\")\n",
    "    ax4.set_ylabel(\"Y\")\n",
    "    ax4.set_zlabel(\"Z\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DLC points.\n",
    "dlc_dir = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_tests/2009_06_18/trail02/run/dlc\"\n",
    "points_dir = \"/Users/zico/Downloads/test2/calb_ext\"\n",
    "n_cams = 3\n",
    "dlc_points_fpaths = sorted(glob(os.path.join(dlc_dir, '*.h5')))\n",
    "points_2d_df = load_dlc_points_as_df(dlc_points_fpaths, verbose=False)\n",
    "filtered_points_2d_df = points_2d_df[points_2d_df['likelihood'] > 0.5]  # ignore points with low likelihood\n",
    "filtered_points_2d_df = filtered_points_2d_df[['camera', 'frame', 'marker', 'x', 'y']]\n",
    "# Add synchronisation offset to the third camera to sync it with cam1 and cam2.\n",
    "filtered_points_2d_df.loc[filtered_points_2d_df['camera'] == 2, \"frame\"] += 259\n",
    "camera_pairs = [[i % n_cams, (i + 1) % n_cams] for i in range(n_cams)]\n",
    "df_list = get_pairwise_points_from_df(filtered_points_2d_df, camera_pairs)\n",
    "markers = [\"tail2\", \"r_back_paw\", \"l_front_ankle\"]\n",
    "for i, (cam_a, cam_b) in enumerate(camera_pairs):\n",
    "    points_df = df_list[i]\n",
    "    generate_pairwise_points(markers, points_df, cam_a, cam_b, points_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot points to visually inspect the 2D points used in the optimisation.\n",
    "plot_points_2d(os.path.join(\"/Users/zico/Downloads/test2/calb_ext/points\", \"points3.json\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic calibration.\n",
    "int_path = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_tests/intrinsic_calib/trail02/cam2\"\n",
    "K, D, R, t, used_points = app.calibrate_arabia_intrinsics(os.path.join(int_path, \"points.json\"), os.path.join(int_path, \"camera.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrinsic calibration.\n",
    "points_fpaths = sorted(glob(os.path.join(\"/Users/zico/Downloads/test2/calb_ext/near_side/points\", \"points[1-4].json\")))\n",
    "scene_fpath = os.path.join(\"/Users/zico/Downloads/test2/calb_ext/near_side\", f\"{len(points_fpaths)}_cam_scene.json\")\n",
    "app.calibrate_arabia_extrinsics(\n",
    "    scene_fpath, points_fpaths[0], points_fpaths[1],\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_tests/intrinsic_calib/trail02/cam1/camera.json\",\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_tests/intrinsic_calib/trail02/cam2/camera.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SBA on calibration points to refine extrinsic calibration parameters.\n",
    "scene_fpath = os.path.join(\"/Users/zico/Downloads/test2/calb_ext/points\", \"3_cam_scene_initial.json\")\n",
    "points_fpaths = sorted(glob(os.path.join(\"/Users/zico/Downloads/test2/calb_ext/points\", \"points[1-4].json\")))\n",
    "scene_sba_fpath = scene_fpath.replace('.json','_sba.json')\n",
    "\n",
    "res, pts_3d, obj_pts = app.sba_extrinsic_params_standard(\n",
    "    scene_fpath, points_fpaths, out_fpath=scene_sba_fpath,\n",
    ")\n",
    "\n",
    "%matplotlib\n",
    "plt.plot(res['before'], label='Cost Before')\n",
    "plt.plot(res['after'], label='Cost After')\n",
    "plt.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "plot_points_3d(pts_3d, \"Estimate Before\")\n",
    "plot_points_3d(obj_pts, \"Estimate After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_fpath = os.path.join(\"/Users/zico/Downloads/test2/calb_ext/points\", \"3_cam_scene_initial_sba.json\")\n",
    "scene_sba_fpath = scene_fpath.replace('.json','_sba_final.json')\n",
    "# Load Measurement Data (pixels, likelihood)\n",
    "points_2d_df = load_dlc_points_as_df(dlc_points_fpaths[:-1], verbose=False)\n",
    "points_2d_df = points_2d_df[points_2d_df['frame'].between(600, 1000)]\n",
    "points_2d_df = points_2d_df[points_2d_df['likelihood']>0.7] # ignore points with low likelihood\n",
    "\n",
    "pts_3d, res = app.sba_points_standard(\n",
    "    scene_fpath, points_2d_df,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(res['before'], label='Cost Before')\n",
    "plt.plot(res['after'], label='Cost After')\n",
    "plt.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "plot_points_3d(pts_3d, \"Estimation of points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene(scene_fpath, points_dir):\n",
    "    pts_2d, frames = [], []\n",
    "    points_fpaths = sorted(glob(os.path.join(points_dir, 'points[1-9].json')))\n",
    "    for fpath in points_fpaths:\n",
    "        img_pts, img_names, *_ = load_points(fpath)\n",
    "        pts_2d.append(img_pts)\n",
    "        frames.append(img_names)\n",
    "\n",
    "    plot_extrinsics(scene_fpath, pts_2d, frames, triangulate_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_fpath = os.path.join(\"/Users/zico/Downloads/test2/calb_ext/points\", \"3_cam_scene_initial_sba_final.json\")\n",
    "plot_scene(scene_fpath, \"/Users/zico/Downloads/test2/calb_ext/points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving new points into the existing points.\n",
    "points = load_json(\"/Users/zico/Downloads/test2/calb_ext/points3.json\")\n",
    "points_orig = load_json(\"/Users/zico/Downloads/test2/calb_ext/points/points3_orig.json\")\n",
    "_, frames, board_shape, board_square_len, cam_res = load_points(\"/Users/zico/Downloads/test2/calb_ext/points/points3_orig.json\")\n",
    "_, new_frames, *_ = load_points(\"/Users/zico/Downloads/test2/calb_ext/points3.json\")\n",
    "for frame in new_frames:\n",
    "    if frame in frames:\n",
    "        points_orig[\"points\"][frame][0][0] = points[\"points\"][frame][0][0]\n",
    "save_json(\"/Users/zico/Downloads/test2/calb_ext/points3_.json\", points_orig)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
