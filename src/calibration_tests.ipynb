{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from lib import app\n",
    "from lib.utils import load_points, save_points, load_json, save_json, load_dlc_points_as_df, load_scene, load_camera\n",
    "from lib.plotting import plot_extrinsics\n",
    "from lib.calib import triangulate_points, project_points\n",
    "\n",
    "plt.style.use(os.path.join(\"..\", \"configs\", \"mplstyle.yaml\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_points(json_paths: list, out_fname: str, pts_per_frame = 5, frame_offset = 0, calib_points = True):\n",
    "    data = load_json(json_paths[0])\n",
    "    output = {\n",
    "        \"board_shape\": [pts_per_frame, 1],\n",
    "        \"board_square_len\": 0,\n",
    "        \"camera_resolution\": [data[\"imageWidth\"], data[\"imageHeight\"]],\n",
    "        \"points\": {}\n",
    "    }\n",
    "    for fname in json_paths:\n",
    "        data = load_json(fname)\n",
    "        if calib_points:\n",
    "            assert len(data[\"shapes\"]) == 9, f\"File {fname} did not produce enough points\"\n",
    "        frame_num = int((data[\"imagePath\"].split(\".png\")[0]).split(\"frame\")[1])\n",
    "        frame_num += frame_offset\n",
    "        output[\"points\"][f\"frame{frame_num}.png\"] = [[np.nan, np.nan]] * pts_per_frame\n",
    "        for i, point in enumerate(data[\"shapes\"]):\n",
    "            if calib_points:\n",
    "                assert f\"p{i+1}\" == point[\"label\"]\n",
    "            p_idx = int(point[\"label\"][-1]) - 1\n",
    "            assert 0 <= p_idx < pts_per_frame, f\"Incorrect point number used: ({p_idx}, {pts_per_frame})\"\n",
    "            output[\"points\"][f\"frame{frame_num}.png\"][p_idx] = (point[\"points\"][0])\n",
    "\n",
    "    save_json(out_fname, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labelme points to acinoset points.\n",
    "# Convert intrinsic points.\n",
    "int_path = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/manual_labels\"\n",
    "cam1_path = sorted(glob(os.path.join(int_path, \"599\", '*.json')))\n",
    "cam2_path = sorted(glob(os.path.join(int_path, \"598\", '*.json')))\n",
    "\n",
    "convert_points(cam1_path, os.path.join(os.path.dirname(int_path), \"cam1\", \"points.json\"), pts_per_frame=9, frame_offset=0)\n",
    "convert_points(cam2_path, os.path.join(os.path.dirname(int_path), \"cam2\", \"points.json\"), pts_per_frame=9, frame_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather DLC labels of tail and spine and obtain pairwise points between the cameras to obtain an estimate of the extrinsics.\n",
    "def get_pairwise_points_from_df(points_2d_df, camera_pairs):\n",
    "    df_list = []\n",
    "    # get pairwise estimates\n",
    "    for cam_a, cam_b in camera_pairs:\n",
    "        d0 = points_2d_df[points_2d_df['camera'] == cam_a]\n",
    "        d1 = points_2d_df[points_2d_df['camera'] == cam_b]\n",
    "        intersection_df = d0.merge(d1, how='inner', on=['frame', 'marker'], suffixes=('_a', '_b'))\n",
    "        if intersection_df.shape[0] > 0:\n",
    "            print(f'Found {intersection_df.shape[0]} pairwise points between camera {cam_a} and {cam_b}')\n",
    "            df_list.append(intersection_df)\n",
    "        else:\n",
    "            print(f'No pairwise points between camera {cam_a} and {cam_b}')\n",
    "\n",
    "    return df_list\n",
    "\n",
    "\n",
    "def get_points_file(n_pts, fname):\n",
    "    try:\n",
    "        output = load_json(fname)\n",
    "    except FileNotFoundError:\n",
    "        output = {\n",
    "            \"board_shape\": [n_pts, 1],\n",
    "            \"board_square_len\": 0,\n",
    "            \"camera_resolution\": [0, 0],\n",
    "            \"points\": {}\n",
    "        }\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_pairwise_points(markers, points_df, cam_a_idx, cam_b_idx, out_dir):\n",
    "    output_a = get_points_file(len(markers), os.path.join(out_dir, f\"points{cam_a_idx+1}.json\"))\n",
    "    output_b = get_points_file(len(markers), os.path.join(out_dir, f\"points{cam_b_idx+1}.json\"))\n",
    "    frames = points_df[\"frame\"].unique()\n",
    "    for fno in frames:\n",
    "        temp_a = []\n",
    "        temp_b = []\n",
    "        for m in markers:\n",
    "            pts_a = points_df.query(f\"frame == {fno} and marker=='{m}'\")[[\"x_a\", \"y_a\"]].values\n",
    "            pts_b = points_df.query(f\"frame == {fno} and marker=='{m}'\")[[\"x_b\", \"y_b\"]].values\n",
    "            temp_a.append(pts_a.squeeze().tolist() if len(pts_a) > 0 else [np.nan, np.nan])\n",
    "            temp_b.append(pts_b.squeeze().tolist() if len(pts_b) > 0 else [np.nan, np.nan])\n",
    "        if len(np.asarray(temp_a, object).shape) == 2 and len(np.asarray(temp_b, object).shape) == 2:\n",
    "            # np.any(~np.isnan(temp_a)) and np.any(~np.isnan(temp_b))\n",
    "            output_a[\"points\"][f\"frame{fno}.png\"] = temp_a\n",
    "            output_b[\"points\"][f\"frame{fno}.png\"] = temp_b\n",
    "\n",
    "    save_json(os.path.join(out_dir, f\"points{cam_a_idx+1}.json\"), output_a)\n",
    "    save_json(os.path.join(out_dir, f\"points{cam_b_idx+1}.json\"), output_b)\n",
    "\n",
    "def plot_points_2d(points_fpath):\n",
    "\n",
    "    points, _, _, _, cam_res = load_points(points_fpath)\n",
    "    plt.figure()\n",
    "    for i in range(points.shape[1]):\n",
    "        plt.scatter(points[:, i, 0], points[:, i, 1], label=f\"p{i+1}\")\n",
    "    plt.xlim((0, cam_res[0]))\n",
    "    plt.ylim((0, cam_res[1]))\n",
    "    plt.legend()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_points_3d(obj_pts, title):\n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(2, 3)\n",
    "    # fig, ax = plt.subplots(2, 3)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    # ax[0, 0].plot(obj_pts[:, 0])\n",
    "    ax1.plot(obj_pts[:, 0])\n",
    "    ax1.set_title(\"X\")\n",
    "    # ax[0, 1].plot(obj_pts[:, 1])\n",
    "    ax2.plot(obj_pts[:, 1])\n",
    "    ax2.set_title(\"Y\")\n",
    "    # ax[0, 2].plot(obj_pts[:, 2])\n",
    "    ax3.plot(obj_pts[:, 1])\n",
    "    ax3.set_title(\"Z\")\n",
    "\n",
    "    # ax = fig.add_subplot(2, 3, (4, 5, 6), projection='3d')\n",
    "    ax4 = fig.add_subplot(gs[1, :], projection='3d')\n",
    "    ax4.scatter(obj_pts[:, 0], obj_pts[:, 1], obj_pts[:, 2])\n",
    "    ax4.set_xlabel(\"X\")\n",
    "    ax4.set_ylabel(\"Y\")\n",
    "    ax4.set_zlabel(\"Z\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DLC points.\n",
    "dlc_dir = \"/Users/zico/Library/CloudStorage/OneDrive-UniversityofCapeTown/msc/data/cheetah_videos/kinetic_dataset/2009_09_07/arabia/trial06/dlc_hand_labeled\"\n",
    "points_dir = \"/Users/zico/Downloads\"\n",
    "n_cams = 4\n",
    "dlc_points_fpaths = sorted(glob(os.path.join(dlc_dir, '*.h5')))\n",
    "points_2d_df = load_dlc_points_as_df(dlc_points_fpaths, hand_labeled=True, verbose=False)\n",
    "# filtered_points_2d_df = points_2d_df[points_2d_df['likelihood'] > 0.8]  # ignore points with low likelihood\n",
    "filtered_points_2d_df = points_2d_df\n",
    "filtered_points_2d_df = filtered_points_2d_df[['camera', 'frame', 'marker', 'x', 'y']]\n",
    "# Add synchronisation offset to the third camera to sync it with cam1 and cam2.\n",
    "filtered_points_2d_df = filtered_points_2d_df[filtered_points_2d_df[\"frame\"] > 50]\n",
    "filtered_points_2d_df.loc[filtered_points_2d_df['camera'] == 2, \"frame\"] -= 5\n",
    "filtered_points_2d_df.loc[filtered_points_2d_df['camera'] == 3, \"frame\"] -= 48\n",
    "camera_pairs = [[i % n_cams, (i + 1) % n_cams] for i in range(n_cams)]\n",
    "df_list = get_pairwise_points_from_df(filtered_points_2d_df, camera_pairs)\n",
    "markers = [\"nose\"]\n",
    "for i, (cam_a, cam_b) in enumerate(camera_pairs):\n",
    "    points_df = df_list[i]\n",
    "    generate_pairwise_points(markers, points_df, cam_a, cam_b, points_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot points to visually inspect the 2D points used in the optimisation.\n",
    "plot_points_2d(\n",
    "    os.path.join(\n",
    "        \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/2009_09_11/extrinsic_calib/stereo/points\",\n",
    "        \"points2.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic calibration.\n",
    "cam_path = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/cam2\"\n",
    "K, D, R, t, used_points = app.calibrate_arabia_intrinsics(os.path.join(cam_path, \"points.json\"),\n",
    "                                                          os.path.join(cam_path, \"camera.json\"),\n",
    "                                                          f=(1042.0, 1042.0),\n",
    "                                                          c=(640.0, 280.0),\n",
    "                                                          reduce_points=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the orientation of the force plates with respect to the cameras.\n",
    "# Then adjust the camera pose so that the first force plate is the world frame.\n",
    "data = load_json(\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/manual_labels/599/frame1.json\"\n",
    ")\n",
    "img_pts = []\n",
    "for i, point in enumerate(data[\"shapes\"]):\n",
    "    img_pts.append(point[\"points\"][0])\n",
    "k, d, _ = load_camera(\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/cam1/camera.json\"\n",
    ")\n",
    "img_pts = np.array(img_pts)\n",
    "obj_pts = np.zeros((6, 3), np.float32)\n",
    "obj_pts[0, :2] = [2.1, -0.45]\n",
    "obj_pts[1, :2] = [2.1, 0.45]\n",
    "obj_pts[2, :2] = [2.7, 0.45]\n",
    "obj_pts[3, :2] = [2.7, -0.45]\n",
    "obj_pts[4, :2] = [1.5, 0.45]\n",
    "obj_pts[5, :2] = [1.5, -0.45]\n",
    "# obj_pts[6, :2] = [0.9, -0.45]\n",
    "# obj_pts[7, :2] = [0.9, 0.45]\n",
    "# obj_pts[8, :2] = [0.3, -0.45]\n",
    "# obj_pts[9, :2] = [-0.3, 0.45]\n",
    "init_t = np.array([[1.5], [1.0], [4.2]])\n",
    "init_r = np.array([[-1.0, 0.0, 0.0], [0.0, 0.0, -1.0], [0.0, -1.0, 0.0]])\n",
    "ret, rvec, tvec = cv.solvePnP(obj_pts,\n",
    "                              img_pts,\n",
    "                              k,\n",
    "                              d,\n",
    "                              useExtrinsicGuess=False,\n",
    "                              rvec=init_r,\n",
    "                              tvec=init_t)\n",
    "ret\n",
    "R = cv.Rodrigues(rvec)[0]\n",
    "R_cam1 = R\n",
    "T_cam1 = tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_cam1\n",
    "R_cam1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrinsic calibration.\n",
    "ext_path = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/2009_09_11/extrinsic_calib/stereo\"\n",
    "points_fpaths = sorted(glob(os.path.join(ext_path, \"points\", \"points[1-4].json\")))\n",
    "scene_fpath = os.path.join(ext_path, f\"{len(points_fpaths)}_cam_scene_test.json\")\n",
    "app.calibrate_arabia_extrinsics(\n",
    "    scene_fpath, points_fpaths[0], points_fpaths[1],\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/cam1/camera.json\",\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/cam2/camera.json\",\n",
    "    R_cam1, T_cam1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SBA on calibration points to refine extrinsic calibration parameters.\n",
    "data_dir = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/2009_09_11/extrinsic_calib/stereo\"\n",
    "scene_fpath = os.path.join(data_dir, \"2_cam_scene_test.json\")\n",
    "points_fpaths = sorted(glob(os.path.join(data_dir, \"points\", \"points[1-4].json\")))\n",
    "scene_sba_fpath = scene_fpath.replace('.json','_sba.json')\n",
    "\n",
    "res, pts_3d, obj_pts = app.sba_extrinsic_params_standard(\n",
    "    scene_fpath, points_fpaths, out_fpath=scene_sba_fpath,\n",
    "    num_view_points=2\n",
    ")\n",
    "\n",
    "plt.plot(res['before'], label='Cost Before')\n",
    "plt.plot(res['after'], label='Cost After')\n",
    "plt.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "plot_points_3d(pts_3d, \"Estimate Before\")\n",
    "plot_points_3d(obj_pts, \"Estimate After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SBA on calibration points to refine extrinsic calibration parameters.\n",
    "data_dir = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_tests/2009_06_18/trail02/extrinsic_calib/manual_calib\"\n",
    "scene_fpath = os.path.join(data_dir, \"3_cam_scene_sba.json\")\n",
    "points_fpaths = sorted(glob(os.path.join(data_dir, \"points\", \"points[1-4].json\")))\n",
    "scene_sba_fpath = scene_fpath.replace('.json','_refined.json')\n",
    "\n",
    "res, pts_3d, obj_pts = app.sba_extrinsic_params_standard(\n",
    "    scene_fpath, points_fpaths, out_fpath=scene_sba_fpath,\n",
    "    num_view_points=2\n",
    ")\n",
    "\n",
    "plt.plot(res['before'], label='Cost Before')\n",
    "plt.plot(res['after'], label='Cost After')\n",
    "plt.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "plot_points_3d(pts_3d, \"Estimate Before\")\n",
    "plot_points_3d(obj_pts, \"Estimate After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SBA on calibration points to refine extrinsic calibration parameters.\n",
    "data_dir = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/2009_09_07/extrinsic_calib\"\n",
    "scene_fpath = os.path.join(data_dir, \"3_cam_scene.json\")\n",
    "points_fpaths = sorted(glob(os.path.join(\"/Users/zico/Downloads\", \"yes\", \"points[1-4].json\")))\n",
    "scene_sba_fpath = scene_fpath.replace('.json', '_final.json')\n",
    "\n",
    "res, pts_3d, obj_pts = app.sba_points_and_extrinsic_params_standard(\n",
    "    scene_fpath,\n",
    "    points_fpaths,\n",
    "    out_fpath=scene_sba_fpath,\n",
    "    robust=True,\n",
    "    # f_scale=100\n",
    ")\n",
    "\n",
    "plt.plot(res['before'], label='Cost Before')\n",
    "plt.plot(res['after'], label='Cost After')\n",
    "plt.legend()\n",
    "plt.show(block=False)\n",
    "\n",
    "plot_points_3d(pts_3d, \"Estimate Before\")\n",
    "plot_points_3d(obj_pts, \"Estimate After\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene(scene_fpath, points_dir, ground_plane_pts=None):\n",
    "    pts_2d, frames = [], []\n",
    "    points_fpaths = sorted(glob(os.path.join(points_dir, 'points[1-9].json')))\n",
    "    for fpath in points_fpaths:\n",
    "        img_pts, img_names, *_ = load_points(fpath)\n",
    "        pts_2d.append(img_pts)\n",
    "        frames.append(img_names)\n",
    "    plot_extrinsics(scene_fpath, pts_2d, frames, triangulate_points, ground_plane_pts=ground_plane_pts, dark_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/2009_09_07/extrinsic_calib/stereo\"\n",
    "plot_scene(os.path.join(data_dir, \"2_cam_scene_test.json\"), os.path.join(\"/Users/zico/Downloads\", \"yes\"))\n",
    "'''\n",
    "[[0.88411592]\n",
    " [0.62751649]\n",
    " [4.55060563]]\n",
    "[[3.84268897]\n",
    " [0.70346261]\n",
    " [4.42031224]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving new points into the existing points.\n",
    "points = load_json(\"/Users/zico/Downloads/test2/calb_ext/points3.json\")\n",
    "points_orig = load_json(\"/Users/zico/Downloads/test2/calb_ext/points/points3_orig.json\")\n",
    "_, frames, board_shape, board_square_len, cam_res = load_points(\"/Users/zico/Downloads/test2/calb_ext/points/points3_orig.json\")\n",
    "_, new_frames, *_ = load_points(\"/Users/zico/Downloads/test2/calb_ext/points3.json\")\n",
    "for frame in new_frames:\n",
    "    if frame in frames:\n",
    "        points_orig[\"points\"][frame][0][0] = points[\"points\"][frame][0][0]\n",
    "save_json(\"/Users/zico/Downloads/test2/calb_ext/points3_.json\", points_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify calibration with reprojection of points on cheetah.\n",
    "def grad(p1, p2):\n",
    "    dx = (p2[0] - p1[0])\n",
    "    dy = (p2[1] - p1[1])\n",
    "    dz = (p2[2] - p1[2])\n",
    "    return dz / dx, dz / dy\n",
    "\n",
    "\n",
    "data_dir = \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/2009_09_11/extrinsic_calib/stereo\"\n",
    "scene_fpath = os.path.join(data_dir, \"2_cam_scene_test.json\")\n",
    "data1 = load_json(\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/manual_labels/599/frame1.json\"\n",
    ")\n",
    "data2 = load_json(\n",
    "    \"/Users/zico/OneDrive - University of Cape Town/msc/data/cheetah_videos/kinetic_dataset/intrinsic_calib/2009_09_11/manual_labels/598/frame1.json\"\n",
    ")\n",
    "img_pts_1 = []\n",
    "img_pts_2 = []\n",
    "for i, point in enumerate(data1[\"shapes\"]):\n",
    "    if i < 4:\n",
    "        img_pts_1.append(point[\"points\"][0])\n",
    "for i, point in enumerate(data2[\"shapes\"]):\n",
    "    if i < 4:\n",
    "        img_pts_2.append(point[\"points\"][0])\n",
    "k_arr, d_arr, r_arr, t_arr, cam_res = load_scene(scene_fpath)\n",
    "n_cams = len(k_arr)\n",
    "pts_3d = triangulate_points(\n",
    "    np.array(img_pts_1), np.array(img_pts_2),\n",
    "    k_arr[0], d_arr[0], r_arr[0], t_arr[0],\n",
    "    k_arr[1], d_arr[1], r_arr[1], t_arr[1]\n",
    ")\n",
    "# Calculate gradients - Should be close to 0!!\n",
    "print(f\"dz/dy: {grad(pts_3d[0], pts_3d[1])[1]}\")  # dy\n",
    "print(f\"dz/dy: {grad(pts_3d[2], pts_3d[3])[1]}\") # dy\n",
    "print(f\"dz/dx: {grad(pts_3d[0], pts_3d[3])[0]}\") # dx\n",
    "print(f\"dz/dx: {grad(pts_3d[1], pts_3d[2])[0]}\") # dx\n",
    "pts_3d = np.append(pts_3d, [pts_3d[0]]).reshape((-1, 3))\n",
    "plot_scene(os.path.join(data_dir, \"2_cam_scene_test.json\"), os.path.join(\"/Users/zico/Downloads\", \"yes\"), ground_plane_pts=pts_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
