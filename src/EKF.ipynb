{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Kalman Filter & Smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from time import time\n",
    "from scipy.stats import linregress\n",
    "from lib import misc, utils, app\n",
    "from lib.calib import project_points_fisheye\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOT_DATA_DIR = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Params\n",
    "Define the params in the cell below. Thereafter, run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, '2019_03_09', 'lily', 'run')\n",
    "\n",
    "start_frame = 70\n",
    "end_frame = 170 # use -1 to reconstruct up to the last frame possible\n",
    "\n",
    "# DLC p_cutoff - any points with likelihood < dlc_thresh are not trusted in optimization\n",
    "dlc_thresh = 0.5 # change this only if the optimization result is unsatisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= INIT VARS ========\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "assert os.path.exists(DATA_DIR), f'Data directory not found: {DATA_DIR}'\n",
    "OUT_DIR = os.path.join(DATA_DIR, 'ekf')\n",
    "DLC_DIR = os.path.join(DATA_DIR, 'dlc')\n",
    "assert os.path.exists(DLC_DIR), f'DLC directory not found: {DLC_DIR}'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "app.start_logging(os.path.join(OUT_DIR, 'ekf.log'))\n",
    "\n",
    "idx = misc.get_pose_params() # define the indices for the states\n",
    "markers = misc.get_markers() # define DLC labels\n",
    "\n",
    "n_markers = len(markers)\n",
    "n_pose_params = len(idx)\n",
    "n_states = 3*n_pose_params\n",
    "vel_idx = n_states//3\n",
    "acc_idx = n_states*2//3\n",
    "\n",
    "derivs = {'d'+state: vel_idx+idx[state] for state in idx}\n",
    "derivs.update({'d'+state: vel_idx+derivs[state] for state in derivs})\n",
    "idx.update(derivs)\n",
    "\n",
    "# load video info\n",
    "res, fps, tot_frames, _ = app.get_vid_info(DATA_DIR) # path to original videos\n",
    "assert end_frame <= tot_frames, f'end_frame must be less than or equal to {tot_frames}'\n",
    "assert end_frame != 0, f'end_frame cannot be 0'\n",
    "if end_frame < 0:\n",
    "    end_frame = end_frame % tot_frames + 1 # cyclic\n",
    "    \n",
    "assert 0 < start_frame < tot_frames, f'start_frame must be strictly between 0 and {tot_frames}'\n",
    "assert 0 <= dlc_thresh <= 1, 'dlc_thresh must be from 0 to 1'\n",
    "\n",
    "with open(os.path.join(OUT_DIR, 'reconstruction_params.json'), 'w') as f:\n",
    "    json.dump(dict(start_frame=start_frame, end_frame=end_frame, dlc_thresh=dlc_thresh), f)\n",
    "\n",
    "# Load extrinsic params\n",
    "k_arr, d_arr, r_arr, t_arr, cam_res, n_cams, scene_fpath = utils.find_scene_file(DATA_DIR)\n",
    "assert res == cam_res\n",
    "camera_params = [[K, D, R, T] for K, D, R, T in zip(k_arr, d_arr, r_arr, t_arr)]\n",
    "\n",
    "# other vars\n",
    "start_frame -= 1 # 0 based indexing\n",
    "n_frames = end_frame-start_frame\n",
    "sigma_bound = 3\n",
    "max_pixel_err = cam_res[0] # used in measurement covariance R\n",
    "sT = 1.0/fps # timestep\n",
    "\n",
    "# ========= FUNCTION DEFINITINOS ========\n",
    "\n",
    "def h_function(x: np.ndarray, k: np.ndarray, d: np.ndarray, r: np.ndarray, t: np.ndarray):\n",
    "    \"\"\"Returns a numpy array of the 2D marker pixel coordinates (shape Nx2) for a given state vector x and camera parameters k, d, r, t.\n",
    "    \"\"\"\n",
    "    coords_3d = misc.get_3d_marker_coords(x)\n",
    "    coords_2d = project_points_fisheye(coords_3d, k, d, r, t) # Project the 3D positions to 2D\n",
    "    \n",
    "    return coords_2d\n",
    "\n",
    "\n",
    "def predict_next_state(x: np.ndarray, dt: np.float32):\n",
    "    \"\"\"Returns a numpy array of the predicted states for a given state vector x and time delta dt.\n",
    "    \"\"\"\n",
    "    acc_prediction = x[acc_idx:]\n",
    "    vel_prediction = x[vel_idx:acc_idx] + dt*acc_prediction\n",
    "    pos_prediction = x[:vel_idx] + dt*vel_prediction + (0.5*dt**2)*acc_prediction\n",
    "    \n",
    "    return np.concatenate([pos_prediction, vel_prediction, acc_prediction]).astype(np.float32)\n",
    "\n",
    "\n",
    "def numerical_jacobian(func, x: np.ndarray, *args):\n",
    "    \"\"\"Returns a numerically approximated jacobian of func with respect to x.\n",
    "    Additional parameters will be passed to func using *args in the format: func(*x, *args)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    eps = 1e-3\n",
    "    \n",
    "    fx = func(x, *args).flatten()\n",
    "    xpeturb=x.copy()\n",
    "    jac = np.empty((len(fx), n))\n",
    "    for i in range(n):\n",
    "        xpeturb[i] = xpeturb[i]+eps\n",
    "        jac[:,i] = (func(xpeturb, *args).flatten() - fx)/eps\n",
    "        xpeturb[i]=x[i]\n",
    "        \n",
    "    return jac\n",
    "\n",
    "\n",
    "# ========= LOAD DLC DATA ========\n",
    "\n",
    "# Load DLC 2D point files (.h5 outputs)\n",
    "dlc_2d_point_files = sorted(glob(os.path.join(DLC_DIR, '*.h5')))\n",
    "assert(len(dlc_2d_point_files) == n_cams), f'# of dlc .h5 files != # of cams in {n_cams}_cam_scene_sba.json'\n",
    "\n",
    "# Load Measurement Data (pixels, likelihood)\n",
    "points_2d_df = utils.load_dlc_points_as_df(dlc_2d_point_files, verbose=False)\n",
    "\n",
    "# Restructure dataframe\n",
    "points_df = points_2d_df.set_index(['frame', 'camera','marker'])\n",
    "points_df = points_df.stack().unstack(level=1).unstack(level=1).unstack()\n",
    "\n",
    "# Pixels array\n",
    "pixels_df = points_df.loc[:, (range(n_cams), markers, ['x','y'])]\n",
    "pixels_df = pixels_df.reindex(columns=pd.MultiIndex.from_product([range(n_cams), markers, ['x','y']]))\n",
    "pixels_arr = pixels_df.to_numpy() #shape - (n_frames, n_cams * n_markers * 2)\n",
    "\n",
    "# Likelihood array\n",
    "likelihood_df = points_df.loc[:, (range(n_cams), markers, 'likelihood')]\n",
    "likelihood_df = likelihood_df.reindex(columns=pd.MultiIndex.from_product([range(n_cams), markers, ['likelihood']]))\n",
    "likelihood_arr = likelihood_df.to_numpy() #shape - (n_frames, n_cams * n_markers * 1)\n",
    "\n",
    "# ========= INITIALIZE EKF MATRICES ========\n",
    "\n",
    "# estimate initial points\n",
    "states = np.zeros(n_states)\n",
    "\n",
    "est_nose_pos, est_nose_vel = app.initialize_marker_3d(\n",
    "    points_2d_df[points_2d_df['frame'].between(start_frame, end_frame-1)],\n",
    "    'nose', k_arr, d_arr, r_arr, t_arr, plot=True\n",
    ")\n",
    "\n",
    "# INITIAL STATES\n",
    "states[[idx['x_0'], idx['y_0'], idx['z_0']]] = est_nose_pos[0, :]   # head x, y, z in inertial\n",
    "states[[idx['dx_0'], idx['dy_0'], idx['z_0']]] = est_nose_vel[0, :] # head x & y velocity in inertial\n",
    "states[idx['psi_0']] = np.arctan2(*est_nose_vel[0, [1, 0]])         # head psi (yaw) in inertial\n",
    "\n",
    "# INITIAL STATE COVARIANCE P - how much do we trust the initial states\n",
    "# position\n",
    "p_lin_pos = np.ones(3)*3**2                       # Know initial position within 4m\n",
    "p_ang_pos = np.ones(n_pose_params-3)*(np.pi/4)**2 # Know initial angles within 60 degrees, heading may need to change\n",
    "# p_lure_pos = p_lin_pos\n",
    "# velocity\n",
    "p_lin_vel = np.ones(3)*5**2                       # Know this within 2.5m/s and it's a uniform random variable\n",
    "p_ang_vel = np.ones(n_pose_params-3)*3**2\n",
    "# p_lure_vel = p_lin_vel\n",
    "# acceleration\n",
    "p_lin_acc = np.ones(3)*3**2\n",
    "p_ang_acc = np.ones(n_pose_params-3)*3**2\n",
    "p_ang_acc[10:] = 5**2\n",
    "# p_lure_acc = p_lin_acc\n",
    "\n",
    "P = np.diag(np.concatenate([p_lin_pos, p_ang_pos, #p_lure_pos,\n",
    "                            p_lin_vel, p_ang_vel, #p_lure_vel,\n",
    "                            p_lin_acc, p_ang_acc, #p_lure_acc\n",
    "                           ]))\n",
    "\n",
    "# PROCESS COVARIANCE Q - how 'noisy' the constant acceleration model is\n",
    "qb_list = [\n",
    "    5.0, 5.0, 5.0,    # head x, y, z in inertial\n",
    "    10.0, 10.0, 10.0, # head phi, theta, psi in inertial\n",
    "    5.0, 25.0, 5.0,   # neck phi, theta, psi\n",
    "    50.0,             # front-torso theta\n",
    "    5.0, 50.0, 25.0,  # back torso phi, theta, psi\n",
    "    100.0, 30.0,      # tail base theta, psi\n",
    "    140.0, 40.0,      # tail mid theta, psi\n",
    "    350.0, 200.0,     # l_shoulder theta, l_front_knee theta\n",
    "    350.0, 200.0,     # r_shoulder theta, r_front_knee theta\n",
    "    450.0, 400.0,     # l_hip theta, l_back_knee theta\n",
    "    450.0, 400.0,     # r_hip theta, r_back_knee theta\n",
    "]\n",
    "# qb_list += qb_list[0:3] # lure x, y, z in inertial - same as head\n",
    "\n",
    "qb = (np.diag(qb_list)/2)**2\n",
    "Q = np.block([\n",
    "    [sT**4/4 * qb, sT**3/2 * qb, sT**2/2 * qb],\n",
    "    [sT**3/2 * qb, sT**2 * qb, sT * qb],\n",
    "    [sT**2/2 * qb, sT * qb, qb],\n",
    "])\n",
    "\n",
    "# MEASUREMENT COVARIANCE R\n",
    "dlc_cov = 5**2\n",
    "\n",
    "# State prediction function jacobian F - shape: (n_states, n_states)\n",
    "rng = np.arange(n_states - vel_idx)\n",
    "rng_acc = np.arange(n_states - acc_idx)\n",
    "F = np.eye(n_states)\n",
    "F[rng, rng+vel_idx] = sT\n",
    "F[rng_acc, rng_acc+acc_idx] = sT**2/2\n",
    "\n",
    "# Allocate space for storing EKF data\n",
    "states_est_hist = np.zeros((n_frames, n_states))\n",
    "states_pred_hist = states_est_hist.copy()\n",
    "P_est_hist = np.zeros((n_frames, n_states, n_states))\n",
    "P_pred_hist = P_est_hist.copy()\n",
    "\n",
    "t1 = time()\n",
    "print(f'\\nInitialization took {t1-t0:.2f} seconds\\n')\n",
    "\n",
    "# ========= RUN EKF & SMOOTHER ========\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "outliers_ignored = 0\n",
    "\n",
    "for i in range(n_frames):\n",
    "    print(f'Running frame {i+start_frame+1}\\r', end='')\n",
    "    \n",
    "    # ========== PREDICTION ==========\n",
    "\n",
    "    # Predict State\n",
    "    states = predict_next_state(states, sT).flatten()\n",
    "    states_pred_hist[i] = states\n",
    "\n",
    "    # Projection of the state covariance\n",
    "    P = F @ P @ F.T + Q\n",
    "    P_pred_hist[i] = P\n",
    "    \n",
    "    # ============ UPDATE ============\n",
    "    \n",
    "    z_k = pixels_arr[i+start_frame]\n",
    "    likelihood = likelihood_arr[i+start_frame]\n",
    "    \n",
    "    # Measurement\n",
    "    H = np.zeros((n_cams*n_markers*2, n_states))\n",
    "    h = np.zeros((n_cams*n_markers*2)) # same as H[:, 0].copy()\n",
    "    for j in range(n_cams):\n",
    "        # State measurement\n",
    "        h[j*n_markers*2:(j+1)*n_markers*2] = h_function(states[:vel_idx], *camera_params[j]).flatten()\n",
    "        # Jacobian - shape: (2*n_markers, n_states)\n",
    "        H[j*n_markers*2:(j+1)*n_markers*2, 0:vel_idx] = numerical_jacobian(h_function, states[:vel_idx], *camera_params[j])\n",
    "    \n",
    "    # Measurement Covariance R\n",
    "    bad_point_mask = np.repeat(likelihood<dlc_thresh, 2)\n",
    "    dlc_cov_arr = dlc_cov*np.ones((n_cams*n_markers*2))\n",
    "    dlc_cov_arr[bad_point_mask] = max_pixel_err # change this to be independent of cam res?\n",
    "    R = np.diag(dlc_cov_arr**2)\n",
    "\n",
    "    # Residual\n",
    "    residual = z_k - h\n",
    "\n",
    "    # Residual Covariance S\n",
    "    S = (H @ P @ H.T) + R\n",
    "    temp = sigma_bound*np.sqrt(np.diag(S)) # if measurement residual is worse than 3 sigma, set residual to 0 and rely on predicted state only\n",
    "    for j in range(0, len(residual), 2):\n",
    "        if np.abs(residual[j])>temp[j] or np.abs(residual[j+1])>temp[j+1]:\n",
    "            residual[j:j+2] = 0\n",
    "            outliers_ignored += 1\n",
    "\n",
    "    # Kalman Gain\n",
    "    K = P @ H.T @ np.linalg.inv(S)\n",
    "\n",
    "    # Correction\n",
    "    states = states + K @ residual\n",
    "    states_est_hist[i] = states\n",
    "\n",
    "    # Update State Covariance\n",
    "    P = (np.eye(K.shape[0]) - K @ H) @ P\n",
    "    P_est_hist[i] = P\n",
    "\n",
    "print('EKF complete!')\n",
    "print('Outliers ignored:', outliers_ignored)\n",
    "\n",
    "# Run Kalman Smoother\n",
    "smooth_states_est_hist = states_est_hist.copy()\n",
    "smooth_P_est_hist = P_est_hist.copy()\n",
    "for i in range(n_frames-2, 0, -1):\n",
    "    A = P_est_hist[i] @ F.T @ np.linalg.inv(P_pred_hist[i+1])\n",
    "    smooth_states_est_hist[i] = states_est_hist[i] + A @ (smooth_states_est_hist[i+1] - states_pred_hist[i+1])\n",
    "    smooth_P_est_hist[i] = P_est_hist[i] + A @ (smooth_P_est_hist[i+1] - P_pred_hist[i+1]) @ A.T\n",
    "    \n",
    "print('\\nKalman Smoother complete!\\n')\n",
    "t1 = time()\n",
    "print(f'Optimization took {t1-t0:.2f} seconds\\n')\n",
    "\n",
    "app.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save EKF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = dict(x=states_est_hist[:, :vel_idx],\n",
    "              dx=states_est_hist[:, vel_idx:acc_idx],\n",
    "              ddx=states_est_hist[:, acc_idx:],\n",
    "              smoothed_x=smooth_states_est_hist[:, :vel_idx],\n",
    "              smoothed_dx=smooth_states_est_hist[:, vel_idx:acc_idx],\n",
    "              smoothed_ddx=smooth_states_est_hist[:, acc_idx:]\n",
    "             )\n",
    "app.save_ekf(states, OUT_DIR, scene_fpath, start_frame, dlc_thresh)\n",
    "\n",
    "fig_fpath= os.path.join(OUT_DIR, 'ekf.svg')\n",
    "app.plot_cheetah_states(states['x'], states['smoothed_x'], fig_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cheetah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = os.path.join(OUT_DIR, 'ekf.pickle')\n",
    "app.plot_cheetah_reconstruction(data_fpath, reprojections=False, centered=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
