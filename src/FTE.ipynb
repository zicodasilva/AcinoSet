{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Trajectory Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pyomo.environ as pyo\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from time import time\n",
    "from scipy.stats import linregress\n",
    "from pyomo.opt import SolverFactory\n",
    "from lib import misc, utils, app\n",
    "from lib.calib import triangulate_points_fisheye\n",
    "\n",
    "plt.style.use(os.path.join('..', 'configs', 'mplstyle.yaml'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOT_DATA_DIR = os.path.join('..', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, '2019_03_09', 'lily', 'run')\n",
    "\n",
    "start_frame = 70\n",
    "end_frame = 170 # use -1 to reconstruct up to the last frame possible\n",
    "\n",
    "# DLC p_cutoff - any points with likelihood < dlc_thresh are not trusted in optimization\n",
    "dlc_thresh = 0.5 # change this only if the optimization result is unsatisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF REDESCENDING, ABSOLUTE AND QUADRATIC COST FUNCTIONS\n",
    "# we use a redescending cost to stop outliers affecting the optimization negatively\n",
    "redesc_a = 3\n",
    "redesc_b = 10\n",
    "redesc_c = 20\n",
    "\n",
    "#Plot\n",
    "r_x  = np.arange(-20,20, 1e-1)\n",
    "r_y1 = [misc.redescending_loss(i, redesc_a, redesc_b, redesc_c) for i in r_x]\n",
    "r_y2 = abs(r_x)\n",
    "r_y3 = r_x**2\n",
    "plt.figure()\n",
    "plt.plot(r_x,r_y1, label='Redescending')\n",
    "plt.plot(r_x,r_y2, label='Absolute (linear)')\n",
    "plt.plot(r_x,r_y3, label='Quadratic')\n",
    "ax = plt.gca()\n",
    "ax.set_ylim((-5, 50))\n",
    "ax.legend()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "assert os.path.exists(DATA_DIR), f'Data directory not found: {DATA_DIR}'\n",
    "OUT_DIR = os.path.join(DATA_DIR, 'fte')\n",
    "DLC_DIR = os.path.join(DATA_DIR, 'dlc')\n",
    "assert os.path.exists(DLC_DIR), f'DLC directory not found: {DLC_DIR}'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "app.start_logging(os.path.join(OUT_DIR, 'fte.log'))\n",
    "\n",
    "# load video info\n",
    "res, fps, tot_frames, _ = app.get_vid_info(DATA_DIR) # path to original videos\n",
    "assert end_frame <= tot_frames, f'end_frame must be less than or equal to {tot_frames}'\n",
    "assert end_frame != 0, f'end_frame cannot be 0'\n",
    "if end_frame < 0:\n",
    "    end_frame = end_frame % tot_frames + 1 # cyclic\n",
    "\n",
    "assert 0 < start_frame < tot_frames, f'start_frame must be strictly between 0 and {tot_frames}'\n",
    "assert 0 <= dlc_thresh <= 1, 'dlc_thresh must be from 0 to 1'\n",
    "\n",
    "with open(os.path.join(OUT_DIR, 'reconstruction_params.json'), 'w') as f:\n",
    "    json.dump(dict(start_frame=start_frame, end_frame=end_frame, dlc_thresh=dlc_thresh), f)\n",
    "\n",
    "start_frame -= 1 # 0 based indexing\n",
    "\n",
    "# symbolic vars\n",
    "idx       = misc.get_pose_params()\n",
    "sym_list  = sp.symbols(list(idx.keys()))\n",
    "positions = misc.get_3d_marker_coords(sym_list)\n",
    "\n",
    "# ========= LAMBDIFY SYMBOLIC FUNCTIONS ========\n",
    "\n",
    "func_map   = {'sin':pyo.sin, 'cos':pyo.cos, 'ImmutableDenseMatrix':np.array}\n",
    "pose_to_3d = sp.lambdify(sym_list, positions, modules=[func_map])\n",
    "pos_funcs  = []\n",
    "for i in range(positions.shape[0]):\n",
    "    lamb = sp.lambdify(sym_list, positions[i,:], modules=[func_map])\n",
    "    pos_funcs.append(lamb)\n",
    "\n",
    "\n",
    "# ========= PROJECTION FUNCTIONS ========\n",
    "\n",
    "def pt3d_to_2d(x, y, z, K, D, R, t):\n",
    "    x_2d = x*R[0,0] + y*R[0,1] + z*R[0,2] + t.flatten()[0]\n",
    "    y_2d = x*R[1,0] + y*R[1,1] + z*R[1,2] + t.flatten()[1]\n",
    "    z_2d = x*R[2,0] + y*R[2,1] + z*R[2,2] + t.flatten()[2]\n",
    "    # project onto camera plane\n",
    "    a    = x_2d/z_2d\n",
    "    b    = y_2d/z_2d\n",
    "    # fisheye params\n",
    "    r    = (a**2 + b**2 +1e-12)**0.5\n",
    "    th   = pyo.atan(r)\n",
    "    # distortion\n",
    "    th_D = th * (1 + D[0]*th**2 + D[1]*th**4 + D[2]*th**6 + D[3]*th**8)\n",
    "    x_P  = a*th_D/r\n",
    "    y_P  = b*th_D/r\n",
    "    u    = K[0,0]*x_P + K[0,2]\n",
    "    v    = K[1,1]*y_P + K[1,2]\n",
    "    return u, v\n",
    "\n",
    "def pt3d_to_x2d(x, y, z, K, D, R, t):\n",
    "    u = pt3d_to_2d(x, y, z, K, D, R, t)[0]\n",
    "    return u\n",
    "\n",
    "def pt3d_to_y2d(x, y, z, K, D, R, t):\n",
    "    v = pt3d_to_2d(x, y, z, K, D, R, t)[1]\n",
    "    return v\n",
    "\n",
    "\n",
    "# ========= IMPORT CAMERA & SCENE PARAMS ========\n",
    "\n",
    "K_arr, D_arr, R_arr, t_arr, cam_res, n_cams, scene_fpath = utils.find_scene_file(DATA_DIR)\n",
    "D_arr = D_arr.reshape((-1,4))\n",
    "assert res == cam_res\n",
    "\n",
    "# ========= IMPORT DATA ========\n",
    "\n",
    "markers = misc.get_markers()\n",
    "\n",
    "R = 5 # measurement standard deviation\n",
    "\n",
    "Q = [ # model parameters variance\n",
    "    4, 7, 5,    # head position in inertial\n",
    "    13, 9, 26,  # head rotation in inertial\n",
    "    32, 18, 12, # neck\n",
    "    43,         # front torso\n",
    "    10, 53, 34, # back torso\n",
    "    90, 43,     # tail_base\n",
    "    118, 51,    # tail_mid\n",
    "    247, 186,   # l_shoulder, l_front_knee\n",
    "    194, 164,   # r_shoulder, r_front_knee\n",
    "    295, 243,   # l_hip, l_back_knee\n",
    "    334, 149    # r_hip, r_back_knee\n",
    "]\n",
    "Q = np.array(Q, dtype=np.float64)**2\n",
    "\n",
    "def get_meas_from_df(n, c, l, d):\n",
    "    n_mask = points_2d_df['frame']  == n-1\n",
    "    l_mask = points_2d_df['marker'] == markers[l-1]\n",
    "    c_mask = points_2d_df['camera'] == c-1\n",
    "    d_idx  = {1:'x', 2:'y'}\n",
    "    val    = points_2d_df[n_mask & l_mask & c_mask]\n",
    "    return val[d_idx[d]].values[0]\n",
    "\n",
    "def get_likelihood_from_df(n, c, l):\n",
    "    n_mask = points_2d_df['frame']  == n-1\n",
    "    l_mask = points_2d_df['marker'] == markers[l-1]\n",
    "    c_mask = points_2d_df['camera'] == c-1\n",
    "    val    = points_2d_df[n_mask & l_mask & c_mask]\n",
    "    return val['likelihood'].values[0]\n",
    "\n",
    "proj_funcs = [pt3d_to_x2d, pt3d_to_y2d]\n",
    "\n",
    "#===================================================\n",
    "#                   Load in data\n",
    "#===================================================\n",
    "\n",
    "print('Loading data')\n",
    "\n",
    "df_paths = sorted(glob(os.path.join(DLC_DIR, '*.h5')))\n",
    "\n",
    "points_2d_df = utils.load_dlc_points_as_df(df_paths, verbose=False)\n",
    "points_3d_df = utils.get_pairwise_3d_points_from_df(\n",
    "    points_2d_df[points_2d_df['likelihood'] > dlc_thresh],\n",
    "    K_arr, D_arr, R_arr, t_arr,\n",
    "    triangulate_points_fisheye\n",
    ")\n",
    "\n",
    "#===================================================\n",
    "#                   Optimisation\n",
    "#===================================================\n",
    "\n",
    "print('Initialising params & variables')\n",
    "m = pyo.ConcreteModel(name = 'Cheetah from measurements')\n",
    "\n",
    "# ===== SETS =====\n",
    "\n",
    "N  = end_frame-start_frame # number of timesteps in trajectory\n",
    "P  = len(sym_list)         # number of pose parameters\n",
    "L  = len(markers)          # number of dlc labels per frame\n",
    "C  = n_cams                # number of cameras\n",
    "D2 = 2                     # dimensionality of measurements (image points)\n",
    "D3 = 3                     # dimensionality of measurements (3d points)\n",
    "\n",
    "m.Ts = 1.0/fps # timestep\n",
    "m.N  = pyo.RangeSet(N)\n",
    "m.P  = pyo.RangeSet(P)\n",
    "m.L  = pyo.RangeSet(L)\n",
    "m.C  = pyo.RangeSet(C)\n",
    "m.D2 = pyo.RangeSet(D2)\n",
    "m.D3 = pyo.RangeSet(D3)\n",
    "\n",
    "# ======= WEIGHTS =======\n",
    "\n",
    "def init_meas_weights(model, n, c, l):\n",
    "    likelihood = get_likelihood_from_df(n+start_frame, c, l)\n",
    "    if likelihood > dlc_thresh:\n",
    "        return 1/R\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def init_model_weights(m, p):\n",
    "    return 1/Q[p-1]\n",
    "\n",
    "def init_measurements_df(m, n, c, l, d2):\n",
    "    return get_meas_from_df(n+start_frame, c, l, d2)\n",
    "\n",
    "m.meas_err_weight  = pyo.Param(m.N, m.C, m.L, initialize = init_meas_weights, mutable=True)\n",
    "m.model_err_weight = pyo.Param(m.P, initialize = init_model_weights)\n",
    "m.meas             = pyo.Param(m.N, m.C, m.L, m.D2, initialize = init_measurements_df)\n",
    "\n",
    "# ===== MODEL VARIABLES =====\n",
    "\n",
    "m.x           = pyo.Var(m.N, m.P) # position\n",
    "m.dx          = pyo.Var(m.N, m.P) # velocity\n",
    "m.ddx         = pyo.Var(m.N, m.P) # acceleration\n",
    "m.poses       = pyo.Var(m.N, m.L, m.D3)\n",
    "m.slack_model = pyo.Var(m.N, m.P)\n",
    "m.slack_meas  = pyo.Var(m.N, m.C, m.L, m.D2, initialize=0.0)\n",
    "\n",
    "# ===== VARIABLES INITIALIZATION =====\n",
    "\n",
    "# estimate initial points\n",
    "frame_est = np.arange(end_frame)\n",
    "init_x    = np.zeros((N, P))\n",
    "init_dx   = np.zeros((N, P))\n",
    "init_ddx  = np.zeros((N, P))\n",
    "\n",
    "nose_pts = points_3d_df[points_3d_df['marker']=='nose'][['frame', 'x', 'y', 'z']].values\n",
    "x_slope, x_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,1])\n",
    "y_slope, y_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,2])\n",
    "z_slope, z_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,3])\n",
    "\n",
    "x_est   = frame_est*x_slope + x_intercept\n",
    "y_est   = frame_est*y_slope + y_intercept\n",
    "z_est   = frame_est*z_slope + z_intercept\n",
    "psi_est = np.arctan2(y_slope, x_slope)\n",
    "\n",
    "init_x[:,idx['x_0']]   = x_est[start_frame: end_frame]\n",
    "init_x[:,idx['y_0']]   = y_est[start_frame: end_frame]\n",
    "init_x[:,idx['z_0']]   = z_est[start_frame: end_frame]\n",
    "init_x[:,idx['psi_0']] = psi_est # psi = yaw\n",
    "\n",
    "for n in m.N:\n",
    "    for p in m.P:\n",
    "        m.x[n,p].value   = init_x[n-1,p-1]\n",
    "        m.dx[n,p].value  = init_dx[n-1,p-1]\n",
    "        m.ddx[n,p].value = init_ddx[n-1,p-1]\n",
    "        # to init using last known value, use m.x[n,p].value = init_x[-1,p-1]\n",
    "    # init pose\n",
    "    var_list = [m.x[n,p].value for p in m.P]\n",
    "    for l in m.L:\n",
    "        [pos] = pos_funcs[l-1](*var_list)\n",
    "        for d3 in m.D3:\n",
    "            m.poses[n,l,d3].value = pos[d3-1]\n",
    "\n",
    "# ===== CONSTRAINTS =====\n",
    "\n",
    "print('Defining constraints')\n",
    "\n",
    "# NOTE: 1 based indexing for pyomo!!!!...@#^!@#&\n",
    "for state in idx:\n",
    "    idx[state] += 1\n",
    "\n",
    "#===== POSE CONSTRAINTS =====\n",
    "\n",
    "print('- Pose')\n",
    "\n",
    "def pose_constraint(m,n,l,d3):\n",
    "    var_list = [m.x[n,p] for p in m.P]\n",
    "    [pos] = pos_funcs[l-1](*var_list) # get 3d points\n",
    "    return pos[d3-1] == m.poses[n,l,d3]\n",
    "\n",
    "m.pose_constraint = pyo.Constraint(m.N, m.L, m.D3, rule = pose_constraint)\n",
    "\n",
    "# define these constraint functions in a loop?\n",
    "# head\n",
    "def head_phi_0(m,n):\n",
    "    return abs(m.x[n,idx['phi_0']]) <= np.pi/6\n",
    "def head_theta_0(m,n):\n",
    "    return abs(m.x[n,idx['theta_0']]) <= np.pi/6\n",
    "\n",
    "# neck\n",
    "def neck_phi_1(m,n):\n",
    "    return abs(m.x[n,idx['phi_1']]) <= np.pi/6\n",
    "def neck_theta_1(m,n):\n",
    "    return abs(m.x[n,idx['theta_1']]) <= np.pi/6\n",
    "def neck_psi_1(m,n):\n",
    "    return abs(m.x[n,idx['psi_1']]) <= np.pi/6\n",
    "\n",
    "# front torso\n",
    "def front_torso_theta_2(m,n):\n",
    "    return abs(m.x[n,idx['theta_2']]) <= np.pi/6\n",
    "\n",
    "# back torso\n",
    "def back_torso_theta_3(m,n):\n",
    "    return abs(m.x[n,idx['theta_3']]) <= np.pi/6\n",
    "def back_torso_phi_3(m,n):\n",
    "    return abs(m.x[n,idx['phi_3']]) <= np.pi/6\n",
    "def back_torso_psi_3(m,n):\n",
    "    return abs(m.x[n,idx['psi_3']]) <= np.pi/6\n",
    "\n",
    "# tail base\n",
    "def tail_base_theta_4(m,n):\n",
    "    return abs(m.x[n,idx['theta_4']]) <= np.pi/1.5\n",
    "def tail_base_psi_4(m,n):\n",
    "    return abs(m.x[n,idx['psi_4']]) <= np.pi/1.5\n",
    "\n",
    "# tail mid\n",
    "def tail_mid_theta_5(m,n):\n",
    "    return abs(m.x[n,idx['theta_5']]) <= np.pi/1.5\n",
    "def tail_mid_psi_5(m,n):\n",
    "    return abs(m.x[n,idx['psi_5']]) <= np.pi/1.5\n",
    "\n",
    "# front left leg\n",
    "def l_shoulder_theta_6(m,n):\n",
    "    return abs(m.x[n,idx['theta_6']]) <= np.pi/2\n",
    "def l_front_knee_theta_7(m,n):\n",
    "    return abs(m.x[n,idx['theta_7']] + np.pi/2) <= np.pi/2\n",
    "\n",
    "# front right leg\n",
    "def r_shoulder_theta_8(m,n):\n",
    "    return abs(m.x[n,idx['theta_8']]) <= np.pi/2\n",
    "def r_front_knee_theta_9(m,n):\n",
    "    return abs(m.x[n,idx['theta_9']] + np.pi/2) <= np.pi/2\n",
    "\n",
    "# back left leg\n",
    "def l_hip_theta_10(m,n):\n",
    "    return abs(m.x[n,idx['theta_10']]) <= np.pi/2\n",
    "def l_back_knee_theta_11(m,n):\n",
    "    return abs(m.x[n,idx['theta_11']] - np.pi/2) <= np.pi/2\n",
    "\n",
    "# back right leg\n",
    "def r_hip_theta_12(m,n):\n",
    "    return abs(m.x[n,idx['theta_12']]) <= np.pi/2\n",
    "def r_back_knee_theta_13(m,n):\n",
    "    return abs(m.x[n,idx['theta_13']] - np.pi/2) <= np.pi/2\n",
    "\n",
    "m.head_phi_0           = pyo.Constraint(m.N, rule = head_phi_0)\n",
    "m.head_theta_0         = pyo.Constraint(m.N, rule = head_theta_0)\n",
    "m.neck_phi_1           = pyo.Constraint(m.N, rule = neck_phi_1)\n",
    "m.neck_theta_1         = pyo.Constraint(m.N, rule = neck_theta_1)\n",
    "m.neck_psi_1           = pyo.Constraint(m.N, rule = neck_psi_1)\n",
    "m.front_torso_theta_2  = pyo.Constraint(m.N, rule = front_torso_theta_2)\n",
    "m.back_torso_theta_3   = pyo.Constraint(m.N, rule = back_torso_theta_3)\n",
    "m.back_torso_phi_3     = pyo.Constraint(m.N, rule = back_torso_phi_3)\n",
    "m.back_torso_psi_3     = pyo.Constraint(m.N, rule = back_torso_psi_3)\n",
    "m.tail_base_theta_4    = pyo.Constraint(m.N, rule = tail_base_theta_4)\n",
    "m.tail_base_psi_4      = pyo.Constraint(m.N, rule = tail_base_psi_4)\n",
    "m.tail_mid_theta_5     = pyo.Constraint(m.N, rule = tail_mid_theta_5)\n",
    "m.tail_mid_psi_5       = pyo.Constraint(m.N, rule = tail_mid_psi_5)\n",
    "m.l_shoulder_theta_6   = pyo.Constraint(m.N, rule = l_shoulder_theta_6)\n",
    "m.l_front_knee_theta_7 = pyo.Constraint(m.N, rule = l_front_knee_theta_7)\n",
    "m.r_shoulder_theta_8   = pyo.Constraint(m.N, rule = r_shoulder_theta_8)\n",
    "m.r_front_knee_theta_9 = pyo.Constraint(m.N, rule = r_front_knee_theta_9)\n",
    "m.l_hip_theta_10       = pyo.Constraint(m.N, rule = l_hip_theta_10)\n",
    "m.l_back_knee_theta_11 = pyo.Constraint(m.N, rule = l_back_knee_theta_11)\n",
    "m.r_hip_theta_12       = pyo.Constraint(m.N, rule = r_hip_theta_12)\n",
    "m.r_back_knee_theta_13 = pyo.Constraint(m.N, rule = r_back_knee_theta_13)\n",
    "\n",
    "# ===== MEASUREMENT CONSTRAINTS =====\n",
    "\n",
    "print('- Measurement')\n",
    "\n",
    "def measurement_constraints(m, n, c, l, d2):\n",
    "    # project\n",
    "    K, D, R, t = K_arr[c-1], D_arr[c-1], R_arr[c-1], t_arr[c-1]\n",
    "    x, y, z    = m.poses[n,l,idx['x_0']], m.poses[n,l,idx['y_0']], m.poses[n,l,idx['z_0']]\n",
    "    return proj_funcs[d2-1](x, y, z, K, D, R, t) - m.meas[n, c, l, d2] - m.slack_meas[n, c, l, d2] == 0\n",
    "\n",
    "m.measurement = pyo.Constraint(m.N, m.C, m.L, m.D2, rule = measurement_constraints)\n",
    "\n",
    "# ===== INTEGRATION CONSTRAINTS =====\n",
    "\n",
    "print('- Numerical integration')\n",
    "\n",
    "def backwards_euler_pos(m,n,p):\n",
    "    if n > 1:\n",
    "        return m.x[n,p] == m.x[n-1,p] + m.Ts*m.dx[n,p]\n",
    "    else:\n",
    "        return pyo.Constraint.Skip\n",
    "\n",
    "def backwards_euler_vel(m,n,p):\n",
    "    if n > 1:\n",
    "        return m.dx[n,p] == m.dx[n-1,p] + m.Ts*m.ddx[n,p]\n",
    "    else:\n",
    "        return pyo.Constraint.Skip\n",
    "\n",
    "def constant_acc(m, n, p):\n",
    "    if n > 1:\n",
    "        return m.ddx[n,p] == m.ddx[n-1,p] + m.slack_model[n,p]\n",
    "    else:\n",
    "        return pyo.Constraint.Skip\n",
    "\n",
    "m.integrate_p  = pyo.Constraint(m.N, m.P, rule = backwards_euler_pos)\n",
    "m.integrate_v  = pyo.Constraint(m.N, m.P, rule = backwards_euler_vel)\n",
    "m.constant_acc = pyo.Constraint(m.N, m.P, rule = constant_acc)\n",
    "\n",
    "# ======= OBJECTIVE FUNCTION =======\n",
    "\n",
    "print('Defining objective function')\n",
    "\n",
    "def obj(m):\n",
    "    slack_model_err, slack_meas_err = 0.0, 0.0\n",
    "    for n in m.N:\n",
    "        # model error\n",
    "        for p in m.P:\n",
    "            slack_model_err += m.model_err_weight[p] * m.slack_model[n, p] ** 2\n",
    "        # measurement error\n",
    "        for l in m.L:\n",
    "            for c in m.C:\n",
    "                for d2 in m.D2:\n",
    "                    slack_meas_err += misc.redescending_loss(m.meas_err_weight[n, c, l] * m.slack_meas[n, c, l, d2], redesc_a, redesc_b, redesc_c)\n",
    "    return slack_meas_err + slack_model_err\n",
    "\n",
    "m.obj = pyo.Objective(rule = obj)\n",
    "\n",
    "# run the solver\n",
    "opt = SolverFactory(\n",
    "    'ipopt',\n",
    "    # executable='./CoinIpopt/build/bin/ipopt'\n",
    ")\n",
    "\n",
    "# solver options\n",
    "opt.options['tol'] = 1e-1\n",
    "opt.options['print_level']  = 5\n",
    "opt.options['max_iter']     = 10000\n",
    "opt.options['max_cpu_time'] = 10000\n",
    "opt.options['OF_print_timing_statistics'] = 'yes'\n",
    "opt.options['OF_print_frequency_iter']    = 10\n",
    "opt.options['OF_hessian_approximation']   = 'limited-memory'\n",
    "# opt.options['linear_solver'] = 'ma86'\n",
    "\n",
    "t1 = time()\n",
    "print('\\nInitialization took {0:.2f} seconds\\n'.format(t1 - t0))\n",
    "\n",
    "t0 = time()\n",
    "results = opt.solve(m, tee=True)\n",
    "t1 = time()\n",
    "print('\\nOptimization took {0:.2f} seconds\\n'.format(t1 - t0))\n",
    "\n",
    "app.stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save FTE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, dx, ddx = [], [], []\n",
    "for n in m.N:\n",
    "    x.append([m.x[n, p].value for p in m.P])\n",
    "    dx.append([m.dx[n, p].value for p in m.P])\n",
    "    ddx.append([m.ddx[n, p].value for p in m.P])\n",
    "\n",
    "app.save_fte(dict(x=x, dx=dx, ddx=ddx), OUT_DIR, scene_fpath, start_frame, dlc_thresh)\n",
    "\n",
    "fig_fpath= os.path.join(OUT_DIR, 'fte.svg')\n",
    "app.plot_cheetah_states(x, out_fpath=fig_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cheetah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = os.path.join(OUT_DIR, 'fte.pickle')\n",
    "app.plot_cheetah_reconstruction(data_fpath, reprojections=False, centered=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
