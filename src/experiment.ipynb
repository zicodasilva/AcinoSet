{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import Dict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from py_utils import data_ops\n",
    "from lib import misc\n",
    "\n",
    "import main_fte\n",
    "\n",
    "plt.style.use(os.path.join(\"../configs\", \"mplstyle.yaml\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load all labelled frames into a pandas dataframe.\n",
    "gt_root_dir = \"/Users/zico/msc/data/gt_labels\"\n",
    "labelled_files = sorted(glob.glob(os.path.join(gt_root_dir, \"**/CollectedData_UCT.h5\"), recursive=True))\n",
    "vid = None\n",
    "for curr_file in labelled_files:\n",
    "    vid = curr_file.split(gt_root_dir + \"/\")[1]\n",
    "    vid = vid.split(\"/\")[0]\n",
    "    # Assuming that cam1 indicates the start of a new video sequence (the videos are sorted above).\n",
    "    cam_idx = int(vid[-1])\n",
    "    if cam_idx == 1:\n",
    "        out_dir = curr_file.split(\"cam1/CollectedData_UCT.h5\")[0]\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "    try:\n",
    "        curr_df = pd.read_hdf(curr_file)\n",
    "    except ValueError:\n",
    "        continue    \n",
    "    start_frame = int(curr_df.index[0].split(\"img\")[1][0:3])\n",
    "    frame_index = range(start_frame, start_frame + len(curr_df.index))\n",
    "    curr_df.index = frame_index\n",
    "    curr_df.to_hdf(os.path.join(out_dir, f\"cam{cam_idx}.h5\"), \"df_with_missing\", format=\"table\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dlc_points_as_df(df_fpaths):\n",
    "    dfs = []\n",
    "    cam_indices = []\n",
    "    for path in df_fpaths:\n",
    "        vid = path.split(\".h5\")[0]\n",
    "        cam_indices.append(int(vid[-1]) - 1)\n",
    "        dlc_df = pd.read_hdf(path)\n",
    "        dlc_df = dlc_df.droplevel([0], axis=1).swaplevel(0,1,axis=1).T.unstack().T.reset_index().rename({'level_0':'frame'}, axis=1)\n",
    "        dlc_df.columns.name = ''\n",
    "        dfs.append(dlc_df)\n",
    "    #create new dataframe\n",
    "    dlc_df = pd.DataFrame(columns=['frame', 'camera', 'marker', 'x', 'y'])\n",
    "    for i, df in enumerate(dfs):\n",
    "        df['camera'] = cam_indices[i]\n",
    "        df.rename(columns={'bodyparts':'marker'}, inplace=True)\n",
    "        dlc_df = pd.concat([dlc_df, df], sort=True, ignore_index=True)\n",
    "\n",
    "    dlc_df = dlc_df[['frame', 'camera', 'marker', 'x', 'y']]\n",
    "    return dlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_dirs = (\"/Users/zico/msc/data/gt_labels/2019_03_09LilyFlick\", \"/Users/zico/msc/data/gt_labels/2019_03_09JulesFlick2\", \"/Users/zico/msc/data/gt_labels/2017_12_16PhantomFlick2_1\", \"/Users/zico/msc/data/gt_labels/2017_09_03ZorroFlick1_1\")\n",
    "for dlc_file in dlc_dirs:\n",
    "    dlc_fpaths = sorted(glob.glob(os.path.join(dlc_file, \"*.h5\")))\n",
    "    res_df = load_dlc_points_as_df(dlc_fpaths)\n",
    "    df = pd.DataFrame(res_df)\n",
    "    ret_name = dlc_file.split(\"/\")[-1]\n",
    "    print(f\"Saving...{ret_name}\")\n",
    "    df.to_csv(os.path.join(dlc_file, f\"{ret_name}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_results_dir = \"/Users/zico/msc/data/PairwiseExperimentResults3\"\n",
    "burst_lengths = (1, 3, 5, 10)\n",
    "num_drop_outs = (0, 20, 40, 60, 80)\n",
    "drop_out_range = (20, 100)\n",
    "\n",
    "# Generate dataset of the manually dropped measurements.\n",
    "drop_out_dataset = {}\n",
    "for burst in burst_lengths:\n",
    "    for num_filtered in num_drop_outs:\n",
    "        drop_out_frames = []\n",
    "        if num_filtered == 0 or num_filtered == 80:\n",
    "            continue\n",
    "        elif burst == 1:\n",
    "             # Randomly select unique frames to drop out.\n",
    "            drop_out_frames = random.sample(range(*drop_out_range), num_filtered)\n",
    "        else:\n",
    "            # Manullay select uniform bursts.\n",
    "            num_bursts = np.ceil(num_filtered / burst)\n",
    "            burst_gaps = np.ceil((drop_out_range[1] - drop_out_range[0]) / num_bursts)\n",
    "            filtered_frames = np.asarray([range(i, i + burst) for i in range(*drop_out_range, int(burst_gaps))]).flatten()\n",
    "            gen_diff = len(filtered_frames) - num_filtered\n",
    "            drop_out_frames = filtered_frames[:-gen_diff] if gen_diff > 0 else filtered_frames\n",
    "\n",
    "        print(f\"({burst}, {num_filtered}): {len(drop_out_frames)}\")\n",
    "        assert len(drop_out_frames) == len(set(drop_out_frames)) and len(drop_out_frames) == num_filtered\n",
    "        drop_out_dataset[(burst, num_filtered)] = drop_out_frames\n",
    "\n",
    "drop_out_dataset[(1, 0)] = []\n",
    "drop_out_dataset[(1, 80)] = list(range(*drop_out_range))\n",
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in drop_out_dataset.items()]), columns=list(drop_out_dataset.keys()))\n",
    "df.to_csv(os.path.join(root_results_dir, \"manual_drop_outs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23T16:27:40.924 | INFO | main_fte: Prepare data - Start\n",
      "2021-08-23T16:27:41.558 | INFO | main_fte: Load H5 2D DLC prediction data\n",
      "2021-08-23T16:27:41.962 | INFO | main_fte: Estimate the initial trajectory\n",
      "2021-08-23T16:27:42.363 | INFO | main_fte: Prepare data - End\n",
      "2021-08-23T16:27:42.367 | INFO | main_fte: Start frame: 9, End frame: 110, Frame rate: 90\n",
      "2021-08-23T16:27:42.370 | INFO | main_fte: Setup optimisation - Start\n",
      "2021-08-23T16:27:42.660 | INFO | main_fte: Measurement initialisation...Done\n",
      "2021-08-23T16:27:46.017 | INFO | main_fte: Variable initialisation...Done\n",
      "2021-08-23T16:28:08.014 | INFO | main_fte: Constaint initialisation...Done\n",
      "2021-08-23T16:28:08.730 | INFO | main_fte: Objective initialisation...Done\n",
      "2021-08-23T16:28:08.734 | INFO | main_fte: Setup optimisation - End\n",
      "2021-08-23T16:28:08.736 | INFO | main_fte: Initialisation took 27.81s\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.join(\"/Users/zico/OneDrive - University of Cape Town/CheetahReconstructionResults/cheetah_videos\")\n",
    "root_results_dir = \"/Users/zico/msc/data/PairwiseExperimentResults3\"\n",
    "burst_lengths = (1, 3, 5, 10)\n",
    "num_drop_outs = (0, 20, 40, 60, 80)\n",
    "drop_out_range = (20, 100)\n",
    "data_path = os.path.join(\"2017_08_29\", \"top\", \"jules\", \"run1_1\")\n",
    "start_frame = 10\n",
    "end_frame = 110\n",
    "dlc_thresh = 0.5\n",
    "\n",
    "tests = (\"Normal\", \"Pairwise\")\n",
    "filtered_markers = (\"r_front_ankle\", \"r_front_paw\", \"r_back_ankle\", \"r_back_paw\")\n",
    "drop_out_dataset = pd.read_csv(os.path.join(root_results_dir, \"manual_drop_outs.csv\"))\n",
    "for test in tests:\n",
    "    for burst in burst_lengths:\n",
    "        for num_filtered in num_drop_outs:\n",
    "            out_prefix = os.path.join(root_results_dir, test, f\"{num_filtered}_percent_{burst}_burst\")\n",
    "            print(f\"Run test: {out_prefix}\")\n",
    "            try:\n",
    "                drop_out_frames = drop_out_dataset[str((burst, num_filtered))].values\n",
    "            except KeyError:\n",
    "                continue\n",
    "            drop_out_frames = drop_out_frames[~np.isnan(drop_out_frames)]\n",
    "            drop_out_frames = drop_out_frames.astype(int).tolist()\n",
    "            # Run the optimisation\n",
    "            main_fte.run(root_dir, data_path, start_frame, end_frame, dlc_thresh, filtered_markers = filtered_markers, drop_out_frames = drop_out_frames,  pairwise_included = 2 if test == \"Pairwise\" else 0, out_dir_prefix=out_prefix)\n",
    "            # Produce results\n",
    "            _, _ = main_fte.metrics(root_dir, data_path, start_frame, end_frame, dlc_thresh, out_dir_prefix=out_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_results_dir = \"/Users/zico/msc/data/PairwiseExperimentResults2\"\n",
    "normal_dir = os.path.join(root_results_dir, \"Normal\")\n",
    "pw_dir = os.path.join(root_results_dir, \"Pairwise\")\n",
    "pw_optimal_dir = os.path.join(root_results_dir, \"PairwiseOptimal\")\n",
    "\n",
    "removed_markers = (\"r_front_ankle\", \"r_front_paw\", \"r_back_ankle\", \"r_back_paw\")\n",
    "tests = (0, 25, 50, 75)\n",
    "plots = [[], [], []]\n",
    "for test in tests:\n",
    "    for i, test_type in enumerate((normal_dir, pw_dir, pw_optimal_dir)):\n",
    "        test_dir = os.path.join(test_type, f\"{test}_percent\")\n",
    "        meas = pd.read_csv(os.path.join(test_dir, \"measurement_results.csv\"))\n",
    "        errors = pd.read_csv(os.path.join(test_dir, \"reprojection_results.csv\"))\n",
    "        errors[\"# meas [%]\"] = meas.iloc[0, 1:].values\n",
    "        data = errors.rename(columns={ \"Unnamed: 0\": \"marker\"})\n",
    "        data = data[[\"marker\", \"mean\", \"std\", \"# meas [%]\"]]\n",
    "        avg_limb_data = data.loc[data[\"marker\"].isin(removed_markers)]\n",
    "        avg_limb_data = avg_limb_data.mean()\n",
    "        avg_data = data.mean()\n",
    "        plots[i].append([*avg_data.values, *avg_limb_data.values])\n",
    "\n",
    "plots = np.asarray(plots)\n",
    "fig = plt.figure(figsize=(12, 12), dpi=120)\n",
    "ax = fig.add_subplot(3, 2, 1)\n",
    "ax.plot(tests, plots[0, :, 0], \"b\")\n",
    "ax.plot(tests, plots[1, :, 0], \"r\")\n",
    "ax.plot(tests, plots[2, :, 0], \"g\")\n",
    "ax.set_title(\"Reprojection Error Mean (Overall)\")\n",
    "ax.set_xticks(tests)\n",
    "ax.set_ylabel(\"Error [px]\")\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 3)\n",
    "ax.plot(tests, plots[0, :, 1], \"b\")\n",
    "ax.plot(tests, plots[1, :, 1], \"r\")\n",
    "ax.plot(tests, plots[2, :, 1], \"g\")\n",
    "ax.set_title(\"Reprojection Error Std Dev (Overall)\")\n",
    "ax.set_xticks(tests)\n",
    "ax.set_ylabel(\"Error [px]\")\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 5)\n",
    "plot_data = ax.plot(tests, plots[0, :, 2], \"b\")\n",
    "plot_data += ax.plot(tests, plots[1, :, 2], \"r\")\n",
    "plot_data += ax.plot(tests, plots[2, :, 2], \"g\")\n",
    "ax.set_title(\"Percentage of Measurements Included (Overall)\")\n",
    "ax.set_xticks(tests)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 2)\n",
    "ax.plot(tests, plots[0, :, 3], \"b\")\n",
    "ax.plot(tests, plots[1, :, 3], \"r\")\n",
    "ax.plot(tests, plots[2, :, 3], \"g\")\n",
    "ax.set_title(\"Reprojection Error Mean (Limbs)\")\n",
    "ax.set_xticks(tests)\n",
    "ax.set_ylabel(\"Error [px]\")\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 4)\n",
    "ax.plot(tests, plots[0, :, 4], \"b\")\n",
    "ax.plot(tests, plots[1, :, 4], \"r\")\n",
    "ax.plot(tests, plots[2, :, 4], \"g\")\n",
    "ax.set_title(\"Reprojection Error Std Dev (Limbs)\")\n",
    "ax.set_xticks(tests)\n",
    "ax.set_ylabel(\"Error [px]\")\n",
    "\n",
    "ax = fig.add_subplot(3, 2, 6)\n",
    "plot_data = ax.plot(tests, plots[0, :, 5], \"b\")\n",
    "plot_data += ax.plot(tests, plots[1, :, 5], \"r\")\n",
    "plot_data += ax.plot(tests, plots[2, :, 5], \"g\")\n",
    "ax.set_title(\"Percentage of Measurements Included (Limbs)\")\n",
    "ax.set_xticks(tests)\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "fig.legend(plot_data, (\"Normal\", \"Pairwise\", \"Optimal Pairwise\"), loc=\"upper right\")\n",
    "fig.text(0.5, 0.007, \"Percentage of Measurements Dropped\", ha='center', va='center')\n",
    "fig.savefig(os.path.join(root_results_dir, \"normal_vs_pw.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pypy] *",
   "language": "python",
   "name": "conda-env-pypy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
