{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import Dict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from py_utils import data_ops\n",
    "from lib import misc\n",
    "\n",
    "import main_fte\n",
    "\n",
    "plt.style.use(os.path.join(\"../configs\", \"mechatronics_style.yaml\"))\n",
    "mechatronics_orange = '#FF6400'\n",
    "mechatronics_charcoal = '#5A5A5A'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First load all labelled frames into a pandas dataframe.\n",
    "gt_root_dir = \"/Users/zico/msc/data/gt_labels\"\n",
    "labelled_files = sorted(glob.glob(os.path.join(gt_root_dir, \"**/CollectedData_UCT.h5\"), recursive=True))\n",
    "vid = None\n",
    "for curr_file in labelled_files:\n",
    "    vid = curr_file.split(gt_root_dir + \"/\")[1]\n",
    "    vid = vid.split(\"/\")[0]\n",
    "    # Assuming that cam1 indicates the start of a new video sequence (the videos are sorted above).\n",
    "    cam_idx = int(vid[-1])\n",
    "    if cam_idx == 1:\n",
    "        out_dir = curr_file.split(\"cam1/CollectedData_UCT.h5\")[0]\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "    try:\n",
    "        curr_df = pd.read_hdf(curr_file)\n",
    "    except ValueError:\n",
    "        continue    \n",
    "    start_frame = int(curr_df.index[0].split(\"img\")[1][0:3])\n",
    "    frame_index = range(start_frame, start_frame + len(curr_df.index))\n",
    "    curr_df.index = frame_index\n",
    "    curr_df.to_hdf(os.path.join(out_dir, f\"cam{cam_idx}.h5\"), \"df_with_missing\", format=\"table\", mode=\"w\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_dlc_points_as_df(df_fpaths):\n",
    "    dfs = []\n",
    "    cam_indices = []\n",
    "    for path in df_fpaths:\n",
    "        vid = path.split(\".h5\")[0]\n",
    "        cam_indices.append(int(vid[-1]) - 1)\n",
    "        dlc_df = pd.read_hdf(path)\n",
    "        dlc_df = dlc_df.droplevel([0], axis=1).swaplevel(0,1,axis=1).T.unstack().T.reset_index().rename({'level_0':'frame'}, axis=1)\n",
    "        dlc_df.columns.name = ''\n",
    "        dfs.append(dlc_df)\n",
    "    #create new dataframe\n",
    "    dlc_df = pd.DataFrame(columns=['frame', 'camera', 'marker', 'x', 'y'])\n",
    "    for i, df in enumerate(dfs):\n",
    "        df['camera'] = cam_indices[i]\n",
    "        df.rename(columns={'bodyparts':'marker'}, inplace=True)\n",
    "        dlc_df = pd.concat([dlc_df, df], sort=True, ignore_index=True)\n",
    "\n",
    "    dlc_df = dlc_df[['frame', 'camera', 'marker', 'x', 'y']]\n",
    "    return dlc_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dlc_dirs = (\"/Users/zico/msc/data/gt_labels/2019_03_09LilyFlick\", \"/Users/zico/msc/data/gt_labels/2019_03_09JulesFlick2\", \"/Users/zico/msc/data/gt_labels/2017_12_16PhantomFlick2_1\", \"/Users/zico/msc/data/gt_labels/2017_09_03ZorroFlick1_1\")\n",
    "for dlc_file in dlc_dirs:\n",
    "    dlc_fpaths = sorted(glob.glob(os.path.join(dlc_file, \"*.h5\")))\n",
    "    res_df = load_dlc_points_as_df(dlc_fpaths)\n",
    "    df = pd.DataFrame(res_df)\n",
    "    ret_name = dlc_file.split(\"/\")[-1]\n",
    "    print(f\"Saving...{ret_name}\")\n",
    "    df.to_csv(os.path.join(dlc_file, f\"{ret_name}.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_results_dir = \"/Users/zico/msc/data/PairwiseExperimentResults4\"\n",
    "burst_lengths = (1, 5, 10, 15, 20)\n",
    "num_drop_outs = (0, 25, 50, 75, 90)\n",
    "drop_out_range = (65, 155)\n",
    "\n",
    "# Generate dataset of the manually dropped measurements.\n",
    "drop_out_dataset = {}\n",
    "for burst in burst_lengths:\n",
    "    for num_filtered in num_drop_outs:\n",
    "        drop_out_frames = []\n",
    "        if num_filtered == 0 or num_filtered == 90:\n",
    "            continue\n",
    "        elif burst == 1:\n",
    "             # Randomly select unique frames to drop out.\n",
    "            drop_out_frames = random.sample(range(*drop_out_range), num_filtered)\n",
    "        else:\n",
    "            # Manullay select uniform bursts.\n",
    "            num_bursts = np.ceil(num_filtered / burst)\n",
    "            burst_gaps = np.ceil((drop_out_range[1] - drop_out_range[0]) / num_bursts)\n",
    "            filtered_frames = np.asarray([range(i, i + burst) for i in range(*drop_out_range, int(burst_gaps))]).flatten()\n",
    "            gen_diff = len(filtered_frames) - num_filtered\n",
    "            drop_out_frames = filtered_frames[:-gen_diff] if gen_diff > 0 else filtered_frames\n",
    "\n",
    "        print(f\"({burst}, {num_filtered}): {len(drop_out_frames)}\")\n",
    "        assert len(drop_out_frames) == len(set(drop_out_frames)) and len(drop_out_frames) == num_filtered\n",
    "        drop_out_dataset[(burst, num_filtered)] = drop_out_frames\n",
    "\n",
    "drop_out_dataset[(1, 0)] = []\n",
    "drop_out_dataset[(1, 90)] = list(range(*drop_out_range))\n",
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in drop_out_dataset.items()]), columns=list(drop_out_dataset.keys()))\n",
    "df.to_csv(os.path.join(root_results_dir, \"manual_drop_outs.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "drop_out_dataset = pd.read_csv(os.path.join(root_results_dir, \"manual_drop_outs.csv\"))\n",
    "tup = (1, 0)\n",
    "drop_out_dataset[str(tup)].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_dir = os.path.join(\"/Users/zico/OneDrive - University of Cape Town/CheetahReconstructionResults/cheetah_videos\")\n",
    "root_results_dir = \"/Users/zico/msc/data/PairwiseExperimentResults3\"\n",
    "burst_lengths = (1, 5, 10, 15)\n",
    "num_drop_outs = (0, 25, 50, 75, 90)\n",
    "drop_out_range = (15, 105)\n",
    "data_path = os.path.join(\"2017_08_29\", \"top\", \"jules\", \"run1_1\")\n",
    "start_frame = 10\n",
    "end_frame = 110\n",
    "dlc_thresh = 0.5\n",
    "\n",
    "# tests = (\"Normal\", \"Pairwise\")\n",
    "tests = (\"Pairwise\")\n",
    "filtered_markers = (\"r_front_ankle\", \"r_front_paw\", \"r_back_ankle\", \"r_back_paw\")\n",
    "drop_out_dataset = pd.read_csv(os.path.join(root_results_dir, \"manual_drop_outs.csv\"))\n",
    "for test in tests:\n",
    "    for burst in burst_lengths:\n",
    "        for num_filtered in num_drop_outs:\n",
    "            out_prefix = os.path.join(root_results_dir, test, f\"{num_filtered}_percent_{burst}_burst\")\n",
    "            try:\n",
    "                drop_out_frames = list(drop_out_dataset[str((burst, num_filtered))].values)\n",
    "            except KeyError:\n",
    "                continue\n",
    "            print(f\"Run test: {out_prefix}\")\n",
    "            # Run the optimisation\n",
    "            main_fte.run(root_dir, data_path, start_frame, end_frame, dlc_thresh, filtered_markers = filtered_markers, drop_out_frames = drop_out_frames,  pairwise_included = 2 if test == \"Pairwise\" else 0, out_dir_prefix=out_prefix)\n",
    "            # Produce results\n",
    "            _, _ = main_fte.metrics(root_dir, data_path, start_frame, end_frame, dlc_thresh, out_dir_prefix=out_prefix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "root_results_dir = \"/Users/zico/msc/data/PairwiseVsNormalExperiment4_reduced\"\n",
    "# test_run_dir = \"2017_08_29/top/jules/run1_1/fte_pw\"\n",
    "test_run_dir = \"2019_03_09/jules/flick1/fte_pw\"\n",
    "normal_dir = os.path.join(root_results_dir, \"Normal\")\n",
    "pw_dir = os.path.join(root_results_dir, \"Pairwise\")\n",
    "\n",
    "# removed_markers = (\"r_front_ankle\", \"r_front_paw\", \"r_back_ankle\", \"r_back_paw\")\n",
    "# removed_markers = (\"l_front_ankle\", \"l_front_paw\", \"l_back_ankle\", \"l_back_paw\", \"r_front_ankle\", \"r_front_paw\", \"r_back_ankle\", \"r_back_paw\")\n",
    "removed_markers = (\"r_front_ankle\", \"r_front_knee\", \"r_back_ankle\", \"r_back_knee\")\n",
    "burst_lengths = (1, 10, 15, 20)\n",
    "num_drop_outs = (0, 25, 50, 75, 90)\n",
    "drop_out_dataset = pd.read_csv(os.path.join(root_results_dir, \"manual_drop_outs.csv\"))\n",
    "valid_tests = drop_out_dataset.columns.values\n",
    "plots = {}\n",
    "for burst in burst_lengths:\n",
    "    plots[burst] = [[], []]\n",
    "    for num_filtered in num_drop_outs:\n",
    "        burst_ = burst\n",
    "        if str((burst, num_filtered)) not in valid_tests:\n",
    "            burst_ = 1\n",
    "        for i, test_type in enumerate((normal_dir, pw_dir)):\n",
    "            test_dir = os.path.join(test_type, f\"{num_filtered}_percent_{burst_}_burst\")\n",
    "            meas = pd.read_csv(os.path.join(test_dir, test_run_dir, \"measurement_results.csv\"))\n",
    "            errors = pd.read_csv(os.path.join(test_dir, test_run_dir, \"reprojection_results.csv\"))\n",
    "            errors[\"# meas [%]\"] = meas.iloc[0, 1:].values\n",
    "            data = errors.rename(columns={ \"Unnamed: 0\": \"marker\"})\n",
    "            data = data[[\"marker\", \"mean\", \"std\", \"# meas [%]\"]]\n",
    "            avg_limb_data = data.loc[data[\"marker\"].isin(removed_markers)]\n",
    "            avg_limb_data = avg_limb_data.mean()\n",
    "            avg_data = data.mean()\n",
    "            plots[burst][i].append([*avg_data.values, *avg_limb_data.values])\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 12), dpi=120)\n",
    "# fig.suptitle(\"Average Reprojection Error\")\n",
    "# for i, burst_plot in enumerate(plots.keys()):\n",
    "#     plotting_data = np.asarray(plots[burst_plot])\n",
    "#     ax = fig.add_subplot(2, 2, i+1)\n",
    "#     plot_data = ax.plot(num_drop_outs[:-1], plotting_data[0, :-1, 0], \"b\")\n",
    "#     plot_data += ax.plot(num_drop_outs[:-1], plotting_data[1, :-1, 0], \"g\")\n",
    "#     ax.set_xticks(num_drop_outs)\n",
    "#     ax.set_title(f\"Burst Length [frames]: {burst_plot}\")\n",
    "\n",
    "# fig.legend(plot_data, (\"Normal\", \"Pairwise\"), loc=\"upper right\")\n",
    "# fig.text(0.5, 0.007, \"Percentage of Measurements Dropped\", ha='center', va='center')\n",
    "# fig.text(0.007, 0.5, \"Error [px]\", ha='center', va='center', rotation='vertical')\n",
    "# fig.savefig(os.path.join(root_results_dir, \"avg_error.pdf\"))\n",
    "\n",
    "burst_type_markers = ('o', 's', 'd', '^', '*')\n",
    "colors = [mechatronics_orange, mechatronics_charcoal]\n",
    "f = lambda m,c: ax.plot([],[],marker=m, color=c, ls=\"none\")[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Average Reprojection Error\")\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, burst_plot in enumerate(plots.keys()):\n",
    "    plotting_data = np.asarray(plots[burst_plot])\n",
    "    ax.plot(num_drop_outs[:-1], plotting_data[0, :-1, 0], color=mechatronics_orange, marker=burst_type_markers[i])\n",
    "    ax.plot(num_drop_outs[:-1], plotting_data[1, :-1, 0], color=mechatronics_charcoal, marker=burst_type_markers[i])\n",
    "    ax.set_xticks(num_drop_outs)\n",
    "\n",
    "handles = [f(\"s\", colors[i]) for i in range(2)]\n",
    "handles += [f(burst_type_markers[i], \"k\") for i in range(5)]\n",
    "labels =  [\"Normal\", \"Pairwise\", \"burst 1\", \"burst 10\", \"burst 15\", \"burst 20\"]\n",
    "\n",
    "ax.legend(handles, labels, loc=\"upper left\", framealpha=1)\n",
    "ax.set_xlabel(\"Percentage of Measurements Dropped\")\n",
    "ax.set_ylabel(\"Error [px]\")\n",
    "fig.savefig(os.path.join(root_results_dir, \"removed_marker_avg_error_.png\"))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Reprojection Standard Deviation\")\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, burst_plot in enumerate(plots.keys()):\n",
    "    plotting_data = np.asarray(plots[burst_plot])\n",
    "    ax.plot(num_drop_outs, plotting_data[0, :, 1], color=mechatronics_orange, marker=burst_type_markers[i])\n",
    "    ax.plot(num_drop_outs, plotting_data[1, :, 1], color=mechatronics_charcoal, marker=burst_type_markers[i])\n",
    "    ax.set_xticks(num_drop_outs)\n",
    "\n",
    "handles = [f(\"s\", colors[i]) for i in range(2)]\n",
    "handles += [f(burst_type_markers[i], \"k\") for i in range(5)]\n",
    "\n",
    "ax.legend(handles, labels, loc=\"upper left\", framealpha=1)\n",
    "ax.set_xlabel(\"Percentage of Measurements Dropped\")\n",
    "ax.set_ylabel(\"Error [px]\")\n",
    "fig.savefig(os.path.join(root_results_dir, \"removed_marker_std_error.png\"))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert 2D ground truth to H5 from pickle format - so this can be used in the metric function in main_fte.\n",
    "p_data = data_ops.load_pickle(\"/Users/zico/Downloads/dive/2D_reprojected_GT.pickle\")\n",
    "bodyparts =  [\"nose\", \"r_eye\", \"l_eye\", \"neck_base\", \"spine\",\n",
    " \"tail_base\", \"tail1\", \"tail2\",\n",
    " \"r_shoulder\", \"r_front_knee\", \"r_front_ankle\", \"r_front_paw\",\n",
    " \"l_shoulder\", \"l_front_knee\",\"l_front_ankle\", \"l_front_paw\",\n",
    " \"r_hip\", \"r_back_knee\", \"r_back_ankle\", \"r_back_paw\",\n",
    " \"l_hip\", \"l_back_knee\", \"l_back_ankle\", \"l_back_paw\"]\n",
    "\n",
    "start_frame = 90\n",
    "gt_data = []\n",
    "p_data.keys()\n",
    "for (frame, cam) in p_data.keys():\n",
    "    d = list(zip(bodyparts, p_data[(frame, cam)]))\n",
    "    d = [(frame + start_frame, cam - 1, b, *list(v)) for (b, v) in d]\n",
    "    gt_data += d\n",
    "\n",
    "df = pd.DataFrame(gt_data, columns=[\"frame\", \"camera\", \"marker\", \"x\", \"y\"])\n",
    "df.to_csv(\"/Users/zico/Downloads/dive/2D_reprojected_GT.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert 3D ground truth to H5 from pickle format - so this can be used in the metric function in main_fte.\n",
    "p_data = data_ops.load_pickle(\"/Users/zico/Downloads/run/3D_GT.pickle\")\n",
    "bodyparts =  [\"nose\", \"r_eye\", \"l_eye\", \"neck_base\", \"spine\",\n",
    " \"tail_base\", \"tail1\", \"tail2\",\n",
    " \"r_shoulder\", \"r_front_knee\", \"r_front_ankle\", \"r_front_paw\",\n",
    " \"l_shoulder\", \"l_front_knee\",\"l_front_ankle\", \"l_front_paw\",\n",
    " \"r_hip\", \"r_back_knee\", \"r_back_ankle\", \"r_back_paw\",\n",
    " \"l_hip\", \"l_back_knee\", \"l_back_ankle\", \"l_back_paw\"]\n",
    "\n",
    "p_data = np.asarray(p_data)\n",
    "start_frame = 60\n",
    "end_frame = 160\n",
    "frames = np.arange(start_frame, end_frame).reshape((-1, 1))\n",
    "n_frames = len(frames)\n",
    "points_3d = []\n",
    "\n",
    "for i, m in enumerate(bodyparts):\n",
    "    _pt3d = np.squeeze(p_data[:, i, :])\n",
    "    marker_arr = np.array([m] * n_frames).reshape((-1, 1))\n",
    "    _pt3d = np.hstack((frames, marker_arr, _pt3d))\n",
    "    points_3d.append(_pt3d)\n",
    "\n",
    "df = pd.DataFrame(np.vstack(points_3d), columns=[\"frame\", \"marker\", \"x\", \"y\", \"z\"]).astype({\n",
    "    \"frame\": \"int64\",\n",
    "    \"marker\": \"str\",\n",
    "    \"x\": \"float64\",\n",
    "    \"y\": \"float64\",\n",
    "    \"z\": \"float64\"\n",
    "})\n",
    "df.to_csv(\"/Users/zico/Downloads/run/3D_GT.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def residual_error_3d(points_3d_GT, points_3d, markers):\n",
    "    error_dfs = []\n",
    "    for m in markers:\n",
    "        # extract frames\n",
    "        q = f'marker == \"{m}\"'\n",
    "        pts_3d = points_3d.query(q)\n",
    "        gt_pts_3d = points_3d_GT.query(q)\n",
    "        pts_3d = pts_3d[pts_3d[['x', 'y', 'z']].notnull().all(axis=1)]\n",
    "        gt_pts_3d = gt_pts_3d[gt_pts_3d[['x', 'y', 'z']].notnull().all(axis=1)]\n",
    "        valid_frames = np.intersect1d(gt_pts_3d['frame'].to_numpy(), pts_3d['frame'].to_numpy())\n",
    "        gt_pts_3d = gt_pts_3d[gt_pts_3d['frame'].isin(valid_frames)].sort_values(by=['frame'])\n",
    "        pts_3d = pts_3d[pts_3d['frame'].isin(valid_frames)].sort_values(by=['frame'])\n",
    "\n",
    "        # get 2d and reprojected points\n",
    "        frames = gt_pts_3d['frame'].to_numpy()\n",
    "        gt_pts = gt_pts_3d[['x', 'y', 'z']].to_numpy()\n",
    "        pts = pts_3d[['x', 'y', 'z']].to_numpy()\n",
    "        if len(gt_pts) == 0 or len(pts) == 0:\n",
    "            continue\n",
    "\n",
    "        # compare both types of points\n",
    "        position_error = np.sqrt(np.sum((gt_pts - pts)**2, axis=1)) * 1000.0\n",
    "        # position_error.shape\n",
    "        # residual = gt_pts - pts\n",
    "\n",
    "        # make the result dataframe\n",
    "        marker_arr = np.array([m] * len(frames))\n",
    "        error_dfs.append(\n",
    "            pd.DataFrame(np.vstack((frames, marker_arr, position_error)).T,\n",
    "                         columns=['frame', 'marker', 'position_error_mm']).astype({\n",
    "        \"frame\": \"int64\",\n",
    "        \"marker\": \"str\",\n",
    "        \"position_error_mm\": \"float64\",\n",
    "    }))\n",
    "\n",
    "    error = pd.concat(error_dfs, ignore_index=True) if len(error_dfs) > 0 else pd.DataFrame(\n",
    "        columns=['frame', 'marker', 'position_error_mm']).astype({\n",
    "        \"frame\": \"int64\",\n",
    "        \"marker\": \"str\",\n",
    "        \"position_error_mm\": \"float64\",\n",
    "    })\n",
    "\n",
    "    return error\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "states = data_ops.load_pickle(\"/Users/zico/msc/dev/AcinoSet/data/2019_03_09/jules/flick1/fte_pw/fte.pickle\")\n",
    "markers = misc.get_markers()\n",
    "start_frame = 60\n",
    "end_frame = 160\n",
    "positions_3ds = misc.get_all_marker_coords_from_states(states, 6)\n",
    "points_3d_dfs = []\n",
    "for positions_3d in positions_3ds:\n",
    "    frames = np.arange(start_frame, end_frame).reshape((-1, 1))\n",
    "    n_frames = len(frames)\n",
    "    points_3d = []\n",
    "    for i, m in enumerate(markers):\n",
    "        _pt3d = np.squeeze(positions_3d[:, i, :])\n",
    "        marker_arr = np.array([m] * n_frames).reshape((-1, 1))\n",
    "        _pt3d = np.hstack((frames, marker_arr, _pt3d))\n",
    "        points_3d.append(_pt3d)\n",
    "    points_3d_df = pd.DataFrame(\n",
    "        np.vstack(points_3d),\n",
    "        columns=[\"frame\", \"marker\", \"x\", \"y\", \"z\"],\n",
    "    ).astype({\n",
    "        \"frame\": \"int64\",\n",
    "        \"marker\": \"str\",\n",
    "        \"x\": \"float64\",\n",
    "        \"y\": \"float64\",\n",
    "        \"z\": \"float64\"\n",
    "    })\n",
    "    points_3d_dfs.append(points_3d_df)\n",
    "# df.query(f'frame == 130 and marker == \"nose\"')\n",
    "# points_3d_dfs[0].query(f' frame == 130 and marker == \"nose\"')\n",
    "error_df = residual_error_3d(df, points_3d_dfs[0], markers)\n",
    "error_df\n",
    "error_df[\"position_error_mm\"].values.mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}